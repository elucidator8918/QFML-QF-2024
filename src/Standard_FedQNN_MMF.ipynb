{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import os\n",
    "os.makedirs('data/MMF', exist_ok=True)\n",
    "!wget -O data/MMF/Audio_Vision_RAVDESS.pkl https://github.com/elucidator8918/MISC/raw/main/Audio_Vision_RAVDESS.pkl\n",
    "\n",
    "import pickle\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from typing import (\n",
    "    List, Tuple, Dict, Optional, Callable, Union\n",
    ")\n",
    "import tenseal as ts\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    Metrics, EvaluateIns, EvaluateRes, FitIns, FitRes, MetricsAggregationFn, \n",
    "    Scalar, logger, ndarrays_to_parameters_custom, parameters_to_ndarrays_custom,\n",
    "    Parameters, NDArrays\n",
    ")\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.strategy.aggregate import weighted_loss_avg\n",
    "from logging import WARNING\n",
    "import pennylane as qml\n",
    "\n",
    "from utils import *\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of FHE Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it exists\n"
     ]
    }
   ],
   "source": [
    "def combo_keys(client_path=\"secret.pkl\", server_path=\"server_key.pkl\"):\n",
    "    \"\"\"\n",
    "    To create the public/private keys combination\n",
    "    args:\n",
    "        client_path: path to save the secret key (str)\n",
    "        server_path: path to save the server public key (str)\n",
    "    \"\"\"\n",
    "    context_client = security.context()\n",
    "    security.write_query(client_path, {\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "    security.write_query(server_path, {\"contexte\": context_client.serialize()})\n",
    "\n",
    "    _, context_client = security.read_query(client_path)\n",
    "    _, context_server = security.read_query(server_path)\n",
    "\n",
    "    context_client = ts.context_from(context_client)\n",
    "    context_server = ts.context_from(context_server)\n",
    "    print(\"Is the client context private?\", (\"Yes\" if context_client.is_private() else \"No\"))\n",
    "    print(\"Is the server context private?\", (\"Yes\" if context_server.is_private() else \"No\"))\n",
    "\n",
    "\n",
    "secret_path = \"secret.pkl\"\n",
    "public_path = \"server_key.pkl\"\n",
    "if os.path.exists(secret_path):\n",
    "    print(\"it exists\")\n",
    "    _, context_client = security.read_query(secret_path)\n",
    "\n",
    "else:\n",
    "    combo_keys(client_path=secret_path, server_path=public_path)\n",
    "\n",
    "n_qubits = 8\n",
    "n_layers = 8\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit.torch\", wires=n_qubits)\n",
    "    \n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_net(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits)) \n",
    "    qml.BasicEntanglerLayers(weights,wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Net, self).__init__()\n",
    "        self.au_rnn1 = nn.LSTM(35, 16, bidirectional=True)\n",
    "        self.au_rnn2 = nn.LSTM(2*16, 16, bidirectional=True)\n",
    "        self.mfccs_rnn1 = nn.LSTM(259, 16, bidirectional=True)\n",
    "        self.mfccs_rnn2 = nn.LSTM(2*16, 16, bidirectional=True)\n",
    "        \n",
    "        self.fusion_layer = nn.Linear(in_features=128, out_features=n_qubits)\n",
    "        self.qnn = qml.qnn.TorchLayer(quantum_net, weight_shapes)\n",
    "        self.out = nn.Linear(n_qubits, num_classes)\n",
    "        self.rnn_map = {\"au\": (self.au_rnn1, self.au_rnn2), \"mfccs\": (self.mfccs_rnn1, self.mfccs_rnn2)}\n",
    "\n",
    "    def extract(self, a, b, task):\n",
    "        rnn1, rnn2 = self.rnn_map[task]\n",
    "        packed_sequence = nn.utils.rnn.pack_padded_sequence(a, b)\n",
    "        packed_h1, (final_h1, _) = rnn1(packed_sequence)\n",
    "        padded_h1, _ = nn.utils.rnn.pad_packed_sequence(packed_h1)\n",
    "        packed_normed_h1 = nn.utils.rnn.pack_padded_sequence(padded_h1, b)\n",
    "        _, (final_h2, _) = rnn2(packed_normed_h1)\n",
    "        extracted = torch.cat((final_h1, final_h2), dim=2).permute(1, 0, 2).contiguous().view(a.size(1), -1)\n",
    "        return extracted\n",
    "\n",
    "    def forward(self, au, mfccs, lengths):\n",
    "        extracted_au = self.extract(au, lengths, task=\"au\")\n",
    "        extracted_mfccs = self.extract(mfccs, lengths, task=\"mfccs\")\n",
    "        au_mfccs_fusion = torch.cat((extracted_au, extracted_mfccs), dim=1)\n",
    "        final_output = self.out(self.qnn(self.fusion_layer(au_mfccs_fusion)))\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FlowerClient class for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader, device, batch_size, save_results, matrix_path, roc_path,\n",
    "                 yaml_path, he, classes, context_client):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.save_results = save_results\n",
    "        self.matrix_path = matrix_path\n",
    "        self.roc_path = roc_path\n",
    "        self.yaml_path = yaml_path\n",
    "        self.he = he\n",
    "        self.classes = classes\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters2(self.net, self.context_client)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        server_round = config['server_round']\n",
    "        local_epochs = config['local_epochs']\n",
    "        lr = float(config[\"learning_rate\"])\n",
    "\n",
    "        print(f'[Client {self.cid}, round {server_round}] fit, config: {config}')\n",
    "\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "        results = engine.train(self.net, self.trainloader, self.valloader, optimizer=optimizer, loss_fn=criterion,\n",
    "                               epochs=local_epochs, device=self.device, task=\"MultiModal\")\n",
    "\n",
    "        if self.save_results:\n",
    "            save_graphs(self.save_results, local_epochs, results, f\"_Client {self.cid}\")\n",
    "\n",
    "        return get_parameters2(self.net, self.context_client), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        loss, accuracy, y_pred, y_true, y_proba = engine.test_multimodal(self.net, self.valloader,\n",
    "                                                              loss_fn=torch.nn.CrossEntropyLoss(), device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            os.makedirs(self.save_results, exist_ok=True)\n",
    "            if self.matrix_path:\n",
    "                save_matrix(y_true, y_pred, self.save_results + self.matrix_path, self.classes)\n",
    "            if self.roc_path:\n",
    "                save_roc(y_true, y_proba, self.save_results + self.roc_path, len(self.classes))\n",
    "\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_common function to set up the Flower client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_common(cid, model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                  batch_size, trainloaders, valloaders, DEVICE, CLASSES,\n",
    "                  he=False, secret_path=\"\", server_path=\"\"):\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    context_client = None\n",
    "    net = Net(num_classes=len(CLASSES)).to(DEVICE)\n",
    "\n",
    "    if he:\n",
    "        print(\"Run with homomorphic encryption\")\n",
    "        if os.path.exists(secret_path):\n",
    "            with open(secret_path, 'rb') as f:\n",
    "                query = pickle.load(f)\n",
    "            context_client = ts.context_from(query[\"contexte\"])\n",
    "        else:\n",
    "            context_client = security.context()\n",
    "            with open(secret_path, 'wb') as f:\n",
    "                encode = pickle.dumps({\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "                f.write(encode)\n",
    "        secret_key = context_client.secret_key()\n",
    "    else:\n",
    "        print(\"Run WITHOUT homomorphic encryption\")\n",
    "\n",
    "    if os.path.exists(model_save):\n",
    "        print(\" To get the checkpoint\")\n",
    "        checkpoint = torch.load(model_save, map_location=DEVICE)['model_state_dict']\n",
    "        if he:\n",
    "            print(\"to decrypt model\")\n",
    "            server_query, server_context = security.read_query(server_path)\n",
    "            server_context = ts.context_from(server_context)\n",
    "            for name in checkpoint:\n",
    "                print(name)\n",
    "                checkpoint[name] = torch.tensor(\n",
    "                    security.deserialized_layer(name, server_query[name], server_context).decrypt(secret_key)\n",
    "                )\n",
    "        net.load_state_dict(checkpoint)\n",
    "\n",
    "    return FlowerClient(cid, net, trainloader, valloader, device=DEVICE, batch_size=batch_size,\n",
    "                        matrix_path=path_matrix, roc_path=path_roc, save_results=results_save, yaml_path=path_yaml,\n",
    "                        he=he, context_client=context_client, classes=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def evaluate2(server_round: int, parameters: NDArrays,\n",
    "              config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    set_parameters(central, parameters)\n",
    "    loss, accuracy, y_pred, y_true, y_proba = engine.test_multimodal(central, testloader, loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                          device=DEVICE)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def get_on_fit_config_fn(epoch=2, lr=0.001, batch_size=32) -> Callable[[int], Dict[str, str]]:\n",
    "    def fit_config(server_round: int) -> Dict[str, str]:\n",
    "        config = {\n",
    "            \"learning_rate\": str(lr),\n",
    "            \"batch_size\": str(batch_size),\n",
    "            \"server_round\": server_round,\n",
    "            \"local_epochs\": epoch\n",
    "        }\n",
    "        return config\n",
    "    return fit_config\n",
    "\n",
    "def aggreg_fit_checkpoint(server_round, aggregated_parameters, central_model, path_checkpoint,\n",
    "                          context_client=None, server_path=\"\"):\n",
    "    if aggregated_parameters is not None:\n",
    "        print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "        aggregated_ndarrays: List[np.ndarray] = parameters_to_ndarrays_custom(aggregated_parameters, context_client)\n",
    "        if context_client:   \n",
    "            server_response = {\"contexte\": server_context.serialize()}\n",
    "            for i, key in enumerate(central_model.state_dict().keys()):\n",
    "                try:\n",
    "                    server_response[key] = aggregated_ndarrays[i].serialize()\n",
    "                except:\n",
    "                    server_response[key] = aggregated_ndarrays[i]\n",
    "            security.write_query(server_path, server_response)\n",
    "        else:\n",
    "            params_dict = zip(central_model.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            central_model.load_state_dict(state_dict, strict=True)\n",
    "            if path_checkpoint:\n",
    "                torch.save({\n",
    "                    'model_state_dict': central_model.state_dict(),\n",
    "                }, path_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FedCustom strategy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Strategy from scratch with the same sampling of the clients as it is in FedAvg\n",
    "# and then change the configuration dictionary\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "            self,\n",
    "            fraction_fit: float = 1.0,\n",
    "            fraction_evaluate: float = 1.0,\n",
    "            min_fit_clients: int = 2,\n",
    "            min_evaluate_clients: int = 2,\n",
    "            min_available_clients: int = 2,\n",
    "            evaluate_fn: Optional[\n",
    "                    Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
    "                ] = None,\n",
    "            on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            accept_failures: bool = True,\n",
    "            initial_parameters: Optional[Parameters] = None,\n",
    "            fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            context_client=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn,\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        return f\"FedCustom (accept_failures={self.accept_failures})\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        initial_parameters = self.initial_parameters\n",
    "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
    "        return initial_parameters\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        # Create custom configs\n",
    "        n_clients = len(clients)\n",
    "        half_clients = n_clients // 2\n",
    "        # Custom fit config function provided\n",
    "        standard_lr = lr\n",
    "        higher_lr = 0.003\n",
    "        config = {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "        if self.on_fit_config_fn is not None:\n",
    "            # Custom fit config function provided\n",
    "            config = self.on_fit_config_fn(server_round)\n",
    "\n",
    "        # fit_ins = FitIns(parameters, config)\n",
    "        # Return client/config pairs\n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            config[\"learning_rate\"] = standard_lr if idx < half_clients else higher_lr\n",
    "            \"\"\"\n",
    "            Each pair of (ClientProxy, FitRes) constitutes \n",
    "            a successful update from one of the previously selected clients.\n",
    "            \"\"\"\n",
    "            fit_configurations.append(\n",
    "                (\n",
    "                    client,\n",
    "                    FitIns(\n",
    "                        parameters,\n",
    "                        config\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        # Successful updates from the previously selected and configured clients\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average. (each round)\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Convert results parameters --> array matrix\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays_custom(fit_res.parameters, self.context_client), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        # Aggregate parameters using weighted average between the clients and convert back to parameters object (bytes)\n",
    "        parameters_aggregated = ndarrays_to_parameters_custom(aggregate_custom(weights_results))\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "\n",
    "        elif server_round == 1:  # Only log this warning once\n",
    "            logger.log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "\n",
    "        # Same function as SaveModelStrategy(fl.server.strategy.FedAvg)\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        aggreg_fit_checkpoint(server_round, parameters_aggregated, central, model_save,\n",
    "                              self.context_client, path_crypted)\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        # Do not configure federated evaluation if fraction eval is 0.\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "\n",
    "        # Parameters and config\n",
    "        config = {}  # {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        # Each pair of (ClientProxy, FitRes) constitutes a successful update from one of the previously selected clients\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Aggregate loss\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.evaluate_metrics_aggregation_fn:\n",
    "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
    "\n",
    "        # Only log this warning once\n",
    "        elif server_round == 1:\n",
    "            logger.log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
    "\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if self.evaluate_fn is None:\n",
    "            # Let's assume we won't perform the global model evaluation on the server side.\n",
    "            return None\n",
    "\n",
    "        # if we have a global model evaluation on the server side :\n",
    "        parameters_ndarrays = parameters_to_ndarrays_custom(parameters, self.context_client)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "\n",
    "        # if you haven't results\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the federated learning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your variables directly\n",
    "he = False\n",
    "data_path = 'data/'\n",
    "dataset = 'MMF'\n",
    "yaml_path = './results/FL/results.yml'\n",
    "seed = 0\n",
    "num_workers = 0\n",
    "max_epochs = 10\n",
    "batch_size = 32\n",
    "splitter = 10\n",
    "device = 'gpu'\n",
    "number_clients = 10\n",
    "save_results = 'results/FL/'\n",
    "matrix_path = 'confusion_matrix.png'\n",
    "roc_path = 'roc.png'\n",
    "model_save = 'MMF_fl.pt'\n",
    "min_fit_clients = 10\n",
    "min_avail_clients = 10\n",
    "min_eval_clients = 10\n",
    "rounds = 20\n",
    "frac_fit = 1.0\n",
    "frac_eval = 0.5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_context = None\n",
    "DEVICE = torch.device(choice_device(device))\n",
    "CLASSES = classes_string(dataset)\n",
    "central = Net(num_classes=len(CLASSES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FedCustom(\n",
    "    fraction_fit=frac_fit,\n",
    "    fraction_evaluate=frac_eval,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_eval_clients if min_eval_clients else number_clients // 2,\n",
    "    min_available_clients=min_avail_clients,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    initial_parameters=ndarrays_to_parameters_custom(get_parameters2(central)),\n",
    "    evaluate_fn=None if he else evaluate2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(epoch=max_epochs, batch_size=batch_size),\n",
    "    context_client=server_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MMF\n",
      "The training set is created for the classes: ('happy', 'sad', 'angry', 'fearful', 'surprise', 'disgust', 'calm', 'neutral')\n"
     ]
    }
   ],
   "source": [
    "trainloaders, valloaders, testloader = data_setup.load_datasets(num_clients=number_clients,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                resize=True,\n",
    "                                                                seed=seed,\n",
    "                                                                num_workers=num_workers,\n",
    "                                                                splitter=splitter,\n",
    "                                                                dataset=dataset,  # Use the specified dataset\n",
    "                                                                data_path=data_path,\n",
    "                                                                data_path_val=None)  # Use the same path for validation data\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    return client_common(cid,\n",
    "                         model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                         batch_size, trainloaders, valloaders, DEVICE, CLASSES, he, secret_path, server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_fn function and set up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:01:55,508 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.5.0\n",
      "numpy 1.26.4\n",
      "torch 2.4.0+cpu\n",
      "torchvision 0.19.0+cpu\n",
      "Training on cpu\n",
      "Start simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-02 10:01:56,694\tWARNING services.py:2017 -- WARNING: The object store is using /tmp instead of /dev/shm because /dev/shm has only 67108864 bytes available. This will harm performance! You may be able to free up space by deleting files in /dev/shm. If you are inside a Docker container, you can increase /dev/shm size by passing '--shm-size=1.73gb' to 'docker run' (or add it to the run_options list in a Ray cluster config). Make sure to set this to more than 30% of available RAM.\n",
      "2024-08-02 10:01:57,780\tINFO worker.py:1781 -- Started a local Ray instance.\n",
      "INFO flwr 2024-08-02 10:01:59,037 | app.py:179 | Flower VCE: Ray initialized with resources: {'object_store_memory': 1691718451.0, 'memory': 3383436903.0, 'node:__internal_head__': 1.0, 'node:10.0.1.195': 1.0, 'CPU': 2.0}\n",
      "INFO flwr 2024-08-02 10:01:59,038 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-08-02 10:01:59,040 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-08-02 10:01:59,041 | server.py:91 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:01:59,315 | server.py:94 | initial parameters (loss, other metrics): 2.0812999407450357, {'accuracy': 14.166666666666666}\n",
      "INFO flwr 2024-08-02 10:01:59,319 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-08-02 10:01:59,320 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.0812999407450357 / accuracy 14.166666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /opt/conda/envs/fed/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 2.1148 | Train_acc: 15.1042 % | Validation_loss: 2.0706 | Validation_acc: 14.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.21it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /opt/conda/envs/fed/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 2.0745 | Train_acc: 13.5417 % | Validation_loss: 2.0848 | Validation_acc: 12.8125 %\u001b[32m [repeated 13x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.29it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.02s/it]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.07s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 2.0993 | Train_acc: 19.0104 % | Validation_loss: 2.1366 | Validation_acc: 3.1250 %\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:08,  1.04s/it]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.13it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.12it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.26it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.22it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.16it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.16it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 2.0252 | Train_acc: 19.0104 % | Validation_loss: 2.1142 | Validation_acc: 4.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.31it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.18it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 2.0777 | Train_acc: 19.7917 % | Validation_loss: 2.0609 | Validation_acc: 16.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.23it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.31it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 2.1374 | Train_acc: 16.1458 % | Validation_loss: 2.1601 | Validation_acc: 9.6875 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.33it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.18it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.16it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.01it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.11it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 2.0771 | Train_acc: 16.1458 % | Validation_loss: 2.1171 | Validation_acc: 9.6875 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.18it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.17it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.11it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.07it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.15it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.17it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.42it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.39it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.42it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 2.1098 | Train_acc: 12.7604 % | Validation_loss: 2.0723 | Validation_acc: 16.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.10it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.14it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.15it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.19it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.10it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 2.0575 | Train_acc: 16.1458 % | Validation_loss: 2.0416 | Validation_acc: 16.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      "DEBUG flwr 2024-08-02 10:02:50,075 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2024-08-02 10:02:50,100 | 3890383987.py:131 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:02:50,313 | server.py:125 | fit progress: (1, 2.0350462595621743, {'accuracy': 14.6875}, 50.993251220000275)\n",
      "DEBUG flwr 2024-08-02 10:02:50,314 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 2.0350462595621743 / accuracy 14.6875\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 2.0265 | Train_acc: 14.3229 % | Validation_loss: 2.0190 | Validation_acc: 24.3750 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:02:56,260 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:02:56,261 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.08s/it]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:10,  1.14s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.11it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.06it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 2.0330 | Train_acc: 17.7083 % | Validation_loss: 2.0687 | Validation_acc: 19.3750 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.23it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.31it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.9149 | Train_acc: 43.7500 % | Validation_loss: 1.9958 | Validation_acc: 30.6250 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.16it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.21it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.16it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.16it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.09it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 2.0088 | Train_acc: 20.5729 % | Validation_loss: 1.9771 | Validation_acc: 32.1875 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.33it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 2.0739 | Train_acc: 11.1979 % | Validation_loss: 2.0721 | Validation_acc: 17.5000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.42it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.9329 | Train_acc: 42.4479 % | Validation_loss: 2.0480 | Validation_acc: 22.5000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.27it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.33it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 2.0220 | Train_acc: 19.7917 % | Validation_loss: 2.0035 | Validation_acc: 16.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.9653 | Train_acc: 33.5938 % | Validation_loss: 2.0059 | Validation_acc: 30.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.28it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.35it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.34it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.9920 | Train_acc: 39.0625 % | Validation_loss: 1.9684 | Validation_acc: 34.0625 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.31it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:03:39,627 | server.py:236 | fit_round 2 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 2 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:03:39,869 | server.py:125 | fit progress: (2, 1.9479294816652934, {'accuracy': 35.520833333333336}, 100.54914903699955)\n",
      "DEBUG flwr 2024-08-02 10:03:39,870 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.9479294816652934 / accuracy 35.520833333333336\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /workspaces/QFML-QF-2024/src/utils/common.py:268: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.9052 | Train_acc: 36.7188 % | Validation_loss: 1.9506 | Validation_acc: 35.9375 %\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   plt.figure(figsize=(12, 7))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /workspaces/QFML-QF-2024/src/utils/common.py:318: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\u001b[32m [repeated 18x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-08-02 10:03:45,787 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:03:45,788 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   plt.figure()\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.23it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.9727 | Train_acc: 33.3333 % | Validation_loss: 1.9290 | Validation_acc: 45.6250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.21it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.13it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /workspaces/QFML-QF-2024/src/utils/common.py:318: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 1.8870 | Train_acc: 39.5833 % | Validation_loss: 1.8812 | Validation_acc: 40.6250 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /workspaces/QFML-QF-2024/src/utils/common.py:399: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   plt.figure()\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.34it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.22it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.9075 | Train_acc: 42.1875 % | Validation_loss: 1.9777 | Validation_acc: 30.6250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /workspaces/QFML-QF-2024/src/utils/common.py:399: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m   plt.figure()\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.7802 | Train_acc: 44.5312 % | Validation_loss: 1.8988 | Validation_acc: 35.6250 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.44it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.40it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.43it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.39it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.32it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.15it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.8513 | Train_acc: 37.5000 % | Validation_loss: 1.9140 | Validation_acc: 30.9375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.31it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.27it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.9233 | Train_acc: 34.8958 % | Validation_loss: 1.9563 | Validation_acc: 27.5000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.33it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.36it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.37it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.17it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.10it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.8843 | Train_acc: 43.7500 % | Validation_loss: 1.9517 | Validation_acc: 30.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.15it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.52it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.39it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.9067 | Train_acc: 35.9375 % | Validation_loss: 1.9747 | Validation_acc: 17.5000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.33it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.34it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.34it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.36it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.33it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      "DEBUG flwr 2024-08-02 10:04:29,218 | server.py:236 | fit_round 3 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 3 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:04:29,456 | server.py:125 | fit progress: (3, 1.8496332168579102, {'accuracy': 37.083333333333336}, 150.13590662000024)\n",
      "DEBUG flwr 2024-08-02 10:04:29,456 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.8496332168579102 / accuracy 37.083333333333336\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.8061 | Train_acc: 35.1562 % | Validation_loss: 1.9396 | Validation_acc: 17.5000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:04:35,344 | server.py:187 | evaluate_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:04:35,345 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /opt/conda/envs/fed/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.22it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.8739 | Train_acc: 38.0208 % | Validation_loss: 1.8220 | Validation_acc: 40.6250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.16it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.20it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.23it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.13it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 1.7022 | Train_acc: 46.0938 % | Validation_loss: 1.8177 | Validation_acc: 38.7500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.11it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.17it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.32it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.8079 | Train_acc: 44.5312 % | Validation_loss: 1.9151 | Validation_acc: 22.5000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.34it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.6855 | Train_acc: 50.0000 % | Validation_loss: 1.8646 | Validation_acc: 19.0625 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.73it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.06s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.51it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.18it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:01<00:04,  1.47it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.39it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.34it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.29it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.7310 | Train_acc: 57.0312 % | Validation_loss: 1.7839 | Validation_acc: 50.3125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.34it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.36it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.26it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.13it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.8133 | Train_acc: 44.7917 % | Validation_loss: 1.9390 | Validation_acc: 20.9375 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.22it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.36it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.37it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.39it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.7302 | Train_acc: 50.5208 % | Validation_loss: 1.7360 | Validation_acc: 54.0625 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.46it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.33it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.7628 | Train_acc: 42.1875 % | Validation_loss: 1.8493 | Validation_acc: 35.6250 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.18it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.24it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.34it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.33it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.32it/s]\n",
      "DEBUG flwr 2024-08-02 10:05:18,048 | server.py:236 | fit_round 4 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 4 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:05:18,338 | server.py:125 | fit progress: (4, 1.737039307753245, {'accuracy': 42.083333333333336}, 199.01807072500014)\n",
      "DEBUG flwr 2024-08-02 10:05:18,339 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.737039307753245 / accuracy 42.083333333333336\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.6569 | Train_acc: 50.0000 % | Validation_loss: 1.7864 | Validation_acc: 35.6250 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:05:24,508 | server.py:187 | evaluate_round 4 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:05:24,509 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.8147 | Train_acc: 36.7188 % | Validation_loss: 1.8193 | Validation_acc: 40.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.38it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.37it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.33it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.34it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.6407 | Train_acc: 47.6562 % | Validation_loss: 1.8127 | Validation_acc: 26.8750 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.29it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.17it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.01it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.12it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.22it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.6372 | Train_acc: 54.6875 % | Validation_loss: 1.6756 | Validation_acc: 50.3125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.30it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.33it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.5298 | Train_acc: 55.7292 % | Validation_loss: 1.8260 | Validation_acc: 33.7500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.54it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.35it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.5940 | Train_acc: 50.0000 % | Validation_loss: 1.7125 | Validation_acc: 48.7500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.33it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.34it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.33it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.37it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.18it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.7111 | Train_acc: 47.6562 % | Validation_loss: 1.8483 | Validation_acc: 27.1875 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:09,  1.13s/it]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:03<00:07,  1.06s/it]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.07it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.22it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.08it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.16it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.6700 | Train_acc: 47.1354 % | Validation_loss: 1.7445 | Validation_acc: 43.7500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.17it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.32it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.6699 | Train_acc: 55.9896 % | Validation_loss: 1.6674 | Validation_acc: 54.0625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.22it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      "DEBUG flwr 2024-08-02 10:06:07,325 | server.py:236 | fit_round 5 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:06:07,570 | server.py:125 | fit progress: (5, 1.6185004909833272, {'accuracy': 44.6875}, 248.24986327999977)\n",
      "DEBUG flwr 2024-08-02 10:06:07,570 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.6185004909833272 / accuracy 44.6875\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.5556 | Train_acc: 54.4271 % | Validation_loss: 1.5877 | Validation_acc: 57.1875 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:06:13,490 | server.py:187 | evaluate_round 5 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:06:13,491 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 10x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.5995 | Train_acc: 43.7500 % | Validation_loss: 1.6504 | Validation_acc: 50.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.03it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.04s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.05it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.04it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.17it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.23it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.23it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.30it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.34it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 1.4624 | Train_acc: 63.8021 % | Validation_loss: 1.7683 | Validation_acc: 32.1875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.15it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.46it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.42it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.42it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.6033 | Train_acc: 50.0000 % | Validation_loss: 1.6053 | Validation_acc: 42.5000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.15it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.26it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.32it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.33it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.4623 | Train_acc: 56.5104 % | Validation_loss: 1.5645 | Validation_acc: 45.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.68it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.41it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.38it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.38it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.5090 | Train_acc: 55.9896 % | Validation_loss: 1.5253 | Validation_acc: 57.1875 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.19it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.7061 | Train_acc: 39.8438 % | Validation_loss: 1.7117 | Validation_acc: 41.8750 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.40it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.15it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.18it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.33it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 1.5500 | Train_acc: 49.2188 % | Validation_loss: 1.7702 | Validation_acc: 25.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.42it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.43it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.42it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.5534 | Train_acc: 46.0938 % | Validation_loss: 1.7059 | Validation_acc: 45.3125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.19it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.36it/s]\n",
      "DEBUG flwr 2024-08-02 10:06:56,576 | server.py:236 | fit_round 6 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.4226 | Train_acc: 54.9479 % | Validation_loss: 1.6552 | Validation_acc: 42.1875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "Saving round 6 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:06:56,842 | server.py:125 | fit progress: (6, 1.5172773400942485, {'accuracy': 52.29166666666667}, 297.5221081889995)\n",
      "DEBUG flwr 2024-08-02 10:06:56,843 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.5172773400942485 / accuracy 52.29166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-08-02 10:07:02,852 | server.py:187 | evaluate_round 6 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:07:02,853 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.5233 | Train_acc: 45.8333 % | Validation_loss: 1.6666 | Validation_acc: 48.7500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.3504 | Train_acc: 57.2917 % | Validation_loss: 1.6393 | Validation_acc: 40.6250 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.43it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.40it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:08,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.4863 | Train_acc: 53.9062 % | Validation_loss: 1.5035 | Validation_acc: 50.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.03it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.36it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.17it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.23it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.02it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.11it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.05it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.3531 | Train_acc: 61.4583 % | Validation_loss: 1.4833 | Validation_acc: 46.5625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:08<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:09<00:00,  1.10it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.20it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.3606 | Train_acc: 67.1875 % | Validation_loss: 1.7184 | Validation_acc: 23.7500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.25it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.5712 | Train_acc: 50.0000 % | Validation_loss: 1.7124 | Validation_acc: 40.0000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.52it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.20it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.35it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.23it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.34it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 1.4125 | Train_acc: 56.5104 % | Validation_loss: 1.7388 | Validation_acc: 36.8750 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.31it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.42it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.41it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3581 | Train_acc: 60.9375 % | Validation_loss: 1.4573 | Validation_acc: 61.8750 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.41it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.35it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.35it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.38it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.42it/s]\n",
      "DEBUG flwr 2024-08-02 10:07:46,472 | server.py:236 | fit_round 7 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 7 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:07:46,736 | server.py:125 | fit progress: (7, 1.4238983194033306, {'accuracy': 53.85416666666667}, 347.41580890800014)\n",
      "DEBUG flwr 2024-08-02 10:07:46,736 | server.py:173 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.4238983194033306 / accuracy 53.85416666666667\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.4502 | Train_acc: 54.9479 % | Validation_loss: 1.5699 | Validation_acc: 53.4375 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:07:52,978 | server.py:187 | evaluate_round 7 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:07:52,979 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 10)\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.12it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.5166 | Train_acc: 45.8333 % | Validation_loss: 1.4403 | Validation_acc: 49.0625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.35it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.2975 | Train_acc: 64.3229 % | Validation_loss: 1.4182 | Validation_acc: 52.1875 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.10it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.44it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:11,  1.26s/it]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.42it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:08,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.2904 | Train_acc: 69.5312 % | Validation_loss: 1.6741 | Validation_acc: 25.3125 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:03<00:06,  1.03it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.20it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.10it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.16it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:08<00:00,  1.14it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.1516 | Train_acc: 75.0000 % | Validation_loss: 1.6552 | Validation_acc: 30.3125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.14it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.40it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.40it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.35it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3107 | Train_acc: 58.8542 % | Validation_loss: 1.3983 | Validation_acc: 55.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.33it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.41it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.5260 | Train_acc: 48.4375 % | Validation_loss: 1.4163 | Validation_acc: 56.5625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.18it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.2875 | Train_acc: 66.4062 % | Validation_loss: 1.4005 | Validation_acc: 45.0000 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.09it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.32it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.2637 | Train_acc: 72.3958 % | Validation_loss: 1.3848 | Validation_acc: 60.0000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.22it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.38it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.35it/s]\n",
      "DEBUG flwr 2024-08-02 10:08:36,368 | server.py:236 | fit_round 8 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 8 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:08:36,606 | server.py:125 | fit progress: (8, 1.3403326272964478, {'accuracy': 56.25}, 397.2860846799995)\n",
      "DEBUG flwr 2024-08-02 10:08:36,606 | server.py:173 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.3403326272964478 / accuracy 56.25\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.1462 | Train_acc: 75.5208 % | Validation_loss: 1.3532 | Validation_acc: 60.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 6] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:08:42,708 | server.py:187 | evaluate_round 8 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:08:42,709 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 10)\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4492 | Train_acc: 48.9583 % | Validation_loss: 1.3648 | Validation_acc: 44.0625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.05it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.05s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.20it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.20it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.16it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.2031 | Train_acc: 67.4479 % | Validation_loss: 1.3459 | Validation_acc: 52.1875 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.58it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:11,  1.25s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.45it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:08,  1.03s/it]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3606 | Train_acc: 53.9062 % | Validation_loss: 1.6017 | Validation_acc: 40.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.19it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.1192 | Train_acc: 66.1458 % | Validation_loss: 1.2589 | Validation_acc: 55.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.2287 | Train_acc: 70.3125 % | Validation_loss: 1.3263 | Validation_acc: 51.5625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.31it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.45it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2141 | Train_acc: 70.0521 % | Validation_loss: 1.3112 | Validation_acc: 65.0000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.33it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.23it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.1315 | Train_acc: 65.8854 % | Validation_loss: 1.5615 | Validation_acc: 40.6250 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.25it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.2413 | Train_acc: 66.1458 % | Validation_loss: 1.2419 | Validation_acc: 63.4375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n",
      "DEBUG flwr 2024-08-02 10:09:25,984 | server.py:236 | fit_round 9 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 9 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:09:26,230 | server.py:125 | fit progress: (9, 1.2623366316159566, {'accuracy': 59.47916666666667}, 446.90996913599975)\n",
      "DEBUG flwr 2024-08-02 10:09:26,230 | server.py:173 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.2623366316159566 / accuracy 59.47916666666667\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.1327 | Train_acc: 63.8021 % | Validation_loss: 1.1802 | Validation_acc: 68.4375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 3] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:09:32,184 | server.py:187 | evaluate_round 9 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:09:32,185 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:10,  1.14s/it]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:10,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.5198 | Train_acc: 40.6250 % | Validation_loss: 1.4383 | Validation_acc: 55.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.11it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.04it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.15it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.19it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.11it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.15it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 1.0413 | Train_acc: 66.9271 % | Validation_loss: 1.1756 | Validation_acc: 63.4375 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.13it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.17it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2087 | Train_acc: 67.7083 % | Validation_loss: 1.4373 | Validation_acc: 53.1250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:07,  1.01s/it]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.12it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.09it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.19it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.20it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 1.0308 | Train_acc: 68.4896 % | Validation_loss: 1.4673 | Validation_acc: 51.5625 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.26it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.32it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 1.0555 | Train_acc: 66.6667 % | Validation_loss: 1.5416 | Validation_acc: 40.6250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.17it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.16it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.20it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2058 | Train_acc: 66.1458 % | Validation_loss: 1.1462 | Validation_acc: 71.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.14it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.13it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 1.0360 | Train_acc: 67.7083 % | Validation_loss: 1.0778 | Validation_acc: 68.1250 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.22it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.39it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.20it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.0349 | Train_acc: 76.5625 % | Validation_loss: 1.5557 | Validation_acc: 33.4375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.34it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "DEBUG flwr 2024-08-02 10:10:16,208 | server.py:236 | fit_round 10 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 10 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:10:16,448 | server.py:125 | fit progress: (10, 1.1735753019650776, {'accuracy': 62.708333333333336}, 497.1285016359998)\n",
      "DEBUG flwr 2024-08-02 10:10:16,449 | server.py:173 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.1735753019650776 / accuracy 62.708333333333336\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.9073 | Train_acc: 78.6458 % | Validation_loss: 1.1869 | Validation_acc: 58.4375 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:10:22,646 | server.py:187 | evaluate_round 10 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:10:22,647 | server.py:222 | fit_round 11: strategy sampled 10 clients (out of 10)\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2004 | Train_acc: 68.4896 % | Validation_loss: 1.0516 | Validation_acc: 66.2500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.18it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.12it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.19it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.25it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 1.1031 | Train_acc: 63.0208 % | Validation_loss: 1.3107 | Validation_acc: 58.4375 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.13it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.14it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.45it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.43it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.9914 | Train_acc: 67.4479 % | Validation_loss: 1.5331 | Validation_acc: 39.0625 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.31it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.9174 | Train_acc: 75.7812 % | Validation_loss: 1.6188 | Validation_acc: 50.0000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.29it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.31it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.33it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.33it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.39it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.43it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 0.8826 | Train_acc: 82.0312 % | Validation_loss: 1.4844 | Validation_acc: 35.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.40it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2649 | Train_acc: 63.5417 % | Validation_loss: 1.1166 | Validation_acc: 71.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.14it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.13it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.32it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.9577 | Train_acc: 72.6562 % | Validation_loss: 1.4160 | Validation_acc: 51.5625 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.1134 | Train_acc: 66.6667 % | Validation_loss: 1.2067 | Validation_acc: 55.3125 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.23it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.14it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.33it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.36it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.8534 | Train_acc: 73.1771 % | Validation_loss: 1.2255 | Validation_acc: 53.7500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n",
      "DEBUG flwr 2024-08-02 10:11:06,133 | server.py:236 | fit_round 11 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 11 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:11:06,382 | server.py:125 | fit progress: (11, 1.091796596844991, {'accuracy': 63.22916666666667}, 547.0619121009995)\n",
      "DEBUG flwr 2024-08-02 10:11:06,382 | server.py:173 | evaluate_round 11: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.091796596844991 / accuracy 63.22916666666667\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.7420 | Train_acc: 79.4271 % | Validation_loss: 1.0929 | Validation_acc: 53.4375 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-08-02 10:11:12,650 | server.py:187 | evaluate_round 11 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:11:12,652 | server.py:222 | fit_round 12: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 9] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.43it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.43it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.38it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.43it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.9586 | Train_acc: 72.6562 % | Validation_loss: 1.2698 | Validation_acc: 53.1250 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.46it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.53it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:06,  1.01s/it]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:05,  1.05s/it]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.01it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.28it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.08it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.15it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.7381 | Train_acc: 78.1250 % | Validation_loss: 1.3967 | Validation_acc: 56.2500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.14it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.10s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.23it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.8010 | Train_acc: 69.0104 % | Validation_loss: 1.5289 | Validation_acc: 42.1875 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.29it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.15it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.18it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6178 | Train_acc: 81.2500 % | Validation_loss: 1.5893 | Validation_acc: 45.6250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.13it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.10it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.29it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.33it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.9453 | Train_acc: 66.1458 % | Validation_loss: 1.3572 | Validation_acc: 60.0000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.19it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.8459 | Train_acc: 79.4271 % | Validation_loss: 1.0551 | Validation_acc: 63.1250 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:06,  1.02s/it]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.18it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.18it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.15it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.25it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.20it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.7091 | Train_acc: 77.8646 % | Validation_loss: 1.2158 | Validation_acc: 55.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.18it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.20it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.9226 | Train_acc: 71.6146 % | Validation_loss: 1.0208 | Validation_acc: 66.2500 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.14it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.19it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.38it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.34it/s]\n",
      "DEBUG flwr 2024-08-02 10:11:56,906 | server.py:236 | fit_round 12 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 12 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:11:57,139 | server.py:125 | fit progress: (12, 1.0543761154015858, {'accuracy': 63.4375}, 597.8194400929997)\n",
      "DEBUG flwr 2024-08-02 10:11:57,140 | server.py:173 | evaluate_round 12: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.0543761154015858 / accuracy 63.4375\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.7205 | Train_acc: 79.6875 % | Validation_loss: 0.9877 | Validation_acc: 63.1250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:12:03,354 | server.py:187 | evaluate_round 12 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:12:03,356 | server.py:222 | fit_round 13: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /opt/conda/envs/fed/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.0887 | Train_acc: 65.1042 % | Validation_loss: 1.2303 | Validation_acc: 50.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.41it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.33it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.39it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.39it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.40it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.40it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.34it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.15it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.6419 | Train_acc: 76.3021 % | Validation_loss: 0.8995 | Validation_acc: 71.8750 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.31it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.15it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.17it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.8042 | Train_acc: 74.2188 % | Validation_loss: 1.5168 | Validation_acc: 53.4375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.12it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.7820 | Train_acc: 75.0000 % | Validation_loss: 1.3846 | Validation_acc: 63.1250 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.35it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.23it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.7353 | Train_acc: 78.9062 % | Validation_loss: 1.3519 | Validation_acc: 54.6875 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.34it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.32it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.44it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.02it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.22it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.7437 | Train_acc: 79.4271 % | Validation_loss: 1.0034 | Validation_acc: 61.5625 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.07it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.18it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6826 | Train_acc: 81.2500 % | Validation_loss: 0.8682 | Validation_acc: 69.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.23it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.6987 | Train_acc: 73.9583 % | Validation_loss: 1.5514 | Validation_acc: 45.3125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.23it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.28it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5115 | Train_acc: 82.8125 % | Validation_loss: 1.6145 | Validation_acc: 48.7500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n",
      "DEBUG flwr 2024-08-02 10:12:47,212 | server.py:236 | fit_round 13 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 13 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:12:47,508 | server.py:125 | fit progress: (13, 1.034390886624654, {'accuracy': 67.39583333333333}, 648.1884953970002)\n",
      "DEBUG flwr 2024-08-02 10:12:47,509 | server.py:173 | evaluate_round 13: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.034390886624654 / accuracy 67.39583333333333\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:12:53,540 | server.py:187 | evaluate_round 13 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:12:53,541 | server.py:222 | fit_round 14: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 8] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.17it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.8045 | Train_acc: 70.5729 % | Validation_loss: 1.2985 | Validation_acc: 51.2500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.08it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.12it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.15it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.17it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.5990 | Train_acc: 80.2083 % | Validation_loss: 1.2604 | Validation_acc: 60.0000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.41it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.11it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.04it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.0110 | Train_acc: 66.1458 % | Validation_loss: 1.2495 | Validation_acc: 63.1250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.14it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.14it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.20it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.16it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.17it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6951 | Train_acc: 78.9062 % | Validation_loss: 1.3573 | Validation_acc: 64.6875 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.14it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.10it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.21it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.19it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.6184 | Train_acc: 77.0833 % | Validation_loss: 0.8791 | Validation_acc: 73.4375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.31it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.16it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.7758 | Train_acc: 76.5625 % | Validation_loss: 0.8698 | Validation_acc: 74.3750 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.33it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.5411 | Train_acc: 84.3750 % | Validation_loss: 0.7991 | Validation_acc: 71.2500 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.53it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.22it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.7250 | Train_acc: 76.5625 % | Validation_loss: 1.5060 | Validation_acc: 60.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.28it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "DEBUG flwr 2024-08-02 10:13:37,704 | server.py:236 | fit_round 14 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 14 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:13:38,001 | server.py:125 | fit progress: (14, 1.009142388900121, {'accuracy': 68.95833333333333}, 698.6814621829999)\n",
      "DEBUG flwr 2024-08-02 10:13:38,002 | server.py:173 | evaluate_round 14: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 1.009142388900121 / accuracy 68.95833333333333\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5614 | Train_acc: 85.1562 % | Validation_loss: 1.6930 | Validation_acc: 61.5625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 5] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:13:44,381 | server.py:187 | evaluate_round 14 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:13:44,383 | server.py:222 | fit_round 15: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.7007 | Train_acc: 73.9583 % | Validation_loss: 1.4798 | Validation_acc: 52.1875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.26it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.5749 | Train_acc: 82.8125 % | Validation_loss: 1.5881 | Validation_acc: 61.5625 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.16it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.15it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.16it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.12it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.19it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.02s/it]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.04s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:08,  1.03s/it]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:08,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.7209 | Train_acc: 78.9062 % | Validation_loss: 1.0564 | Validation_acc: 59.6875 %\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.10it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.05it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.15it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.15it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.19it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.23it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.4819 | Train_acc: 89.0625 % | Validation_loss: 1.2618 | Validation_acc: 60.0000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.17it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.14it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.14it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.41it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.40it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 0.5849 | Train_acc: 77.8646 % | Validation_loss: 0.8624 | Validation_acc: 73.4375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.8040 | Train_acc: 77.8646 % | Validation_loss: 0.9407 | Validation_acc: 66.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.34it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.33it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.36it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6930 | Train_acc: 79.6875 % | Validation_loss: 1.2976 | Validation_acc: 64.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.14it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.32it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.6429 | Train_acc: 77.3438 % | Validation_loss: 0.7523 | Validation_acc: 77.8125 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.33it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.4696 | Train_acc: 85.9375 % | Validation_loss: 0.8962 | Validation_acc: 73.1250 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "DEBUG flwr 2024-08-02 10:14:28,712 | server.py:236 | fit_round 15 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 15 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:14:28,983 | server.py:125 | fit progress: (15, 0.9797761837641398, {'accuracy': 67.91666666666667}, 749.6629356220001)\n",
      "DEBUG flwr 2024-08-02 10:14:28,983 | server.py:173 | evaluate_round 15: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9797761837641398 / accuracy 67.91666666666667\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4510 | Train_acc: 85.9375 % | Validation_loss: 0.8974 | Validation_acc: 73.1250 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:14:35,020 | server.py:187 | evaluate_round 15 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:14:35,022 | server.py:222 | fit_round 16: strategy sampled 10 clients (out of 10)\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 0, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.01s/it]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.06it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.17it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.17it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.5046 | Train_acc: 82.8125 % | Validation_loss: 1.4850 | Validation_acc: 60.3125 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.11it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.17it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.20it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.22it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.14it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.19it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.3591 | Train_acc: 88.2812 % | Validation_loss: 1.5467 | Validation_acc: 55.3125 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.19it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.39it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.16it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.3950 | Train_acc: 87.5000 % | Validation_loss: 1.3005 | Validation_acc: 46.5625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.15it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.16it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.42it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.6477 | Train_acc: 78.1250 % | Validation_loss: 0.8334 | Validation_acc: 72.8125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.41it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.39it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.45it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:07,  1.09s/it]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.09it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.13it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.33it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6036 | Train_acc: 82.0312 % | Validation_loss: 1.2721 | Validation_acc: 66.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.14it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.45it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.38it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.6187 | Train_acc: 80.4688 % | Validation_loss: 1.2153 | Validation_acc: 64.3750 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.7528 | Train_acc: 78.6458 % | Validation_loss: 0.9366 | Validation_acc: 64.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.34it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.35it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.3774 | Train_acc: 91.4062 % | Validation_loss: 1.0195 | Validation_acc: 55.0000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.37it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.35it/s]\n",
      "DEBUG flwr 2024-08-02 10:15:19,191 | server.py:236 | fit_round 16 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 16 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:15:19,426 | server.py:125 | fit progress: (16, 0.9481822649637858, {'accuracy': 68.4375}, 800.1061192279994)\n",
      "DEBUG flwr 2024-08-02 10:15:19,426 | server.py:173 | evaluate_round 16: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9481822649637858 / accuracy 68.4375\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4204 | Train_acc: 91.4062 % | Validation_loss: 1.2770 | Validation_acc: 60.0000 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:15:25,560 | server.py:187 | evaluate_round 16 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:15:25,561 | server.py:222 | fit_round 17: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 19x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 7, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.16it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6193 | Train_acc: 82.0312 % | Validation_loss: 1.1871 | Validation_acc: 56.2500 %\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6991 | Train_acc: 79.4271 % | Validation_loss: 0.9450 | Validation_acc: 63.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.18it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.19it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:03<00:08,  1.21s/it]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:04<00:06,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.02it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.3797 | Train_acc: 89.8438 % | Validation_loss: 1.0428 | Validation_acc: 50.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:06<00:04,  1.01s/it]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.09it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.17it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:08<00:00,  1.10it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:09<00:00,  1.08it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.5287 | Train_acc: 82.8125 % | Validation_loss: 0.7229 | Validation_acc: 77.8125 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.16it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.15it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.16it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.20it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.3501 | Train_acc: 92.1875 % | Validation_loss: 1.4541 | Validation_acc: 63.4375 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.22it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.09it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5263 | Train_acc: 87.5000 % | Validation_loss: 0.8420 | Validation_acc: 76.5625 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.33it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.18it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.20it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.14it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4049 | Train_acc: 92.1875 % | Validation_loss: 0.9800 | Validation_acc: 76.5625 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.30it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.33it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.4343 | Train_acc: 86.7188 % | Validation_loss: 0.8852 | Validation_acc: 73.1250 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.05it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.14it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.40it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.5668 | Train_acc: 80.2083 % | Validation_loss: 1.3077 | Validation_acc: 66.5625 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.37it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.33it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.5082 | Train_acc: 85.9375 % | Validation_loss: 1.2600 | Validation_acc: 64.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.36it/s]\n",
      "DEBUG flwr 2024-08-02 10:16:10,120 | server.py:236 | fit_round 17 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 17 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:16:10,404 | server.py:125 | fit progress: (17, 0.9155133565266927, {'accuracy': 68.4375}, 851.084520286)\n",
      "DEBUG flwr 2024-08-02 10:16:10,405 | server.py:173 | evaluate_round 17: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9155133565266927 / accuracy 68.4375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4685 | Train_acc: 86.7188 % | Validation_loss: 1.2522 | Validation_acc: 67.8125 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:16:17,016 | server.py:187 | evaluate_round 17 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:16:17,017 | server.py:222 | fit_round 18: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 8, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.14it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.6584 | Train_acc: 77.0833 % | Validation_loss: 1.3337 | Validation_acc: 62.8125 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.21it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.17it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.19it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.25it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.10it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.07it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.16it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.4146 | Train_acc: 89.0625 % | Validation_loss: 1.6461 | Validation_acc: 58.1250 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.17it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.11it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 9, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.37it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.25it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.31it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.19it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5869 | Train_acc: 78.9062 % | Validation_loss: 1.1540 | Validation_acc: 67.8125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.23it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.17it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.16it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.21it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4208 | Train_acc: 89.0625 % | Validation_loss: 1.1986 | Validation_acc: 67.8125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.20it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.24it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.25it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.33it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.4387 | Train_acc: 92.9688 % | Validation_loss: 0.9217 | Validation_acc: 75.0000 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 3, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.22it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.09it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.12it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.16it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.20it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.21it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 4, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.36it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.8156 | Train_acc: 73.1771 % | Validation_loss: 0.7667 | Validation_acc: 73.1250 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.39it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.21it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.28it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.29it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.3470 | Train_acc: 90.6250 % | Validation_loss: 0.8686 | Validation_acc: 73.1250 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.31it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.13it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.03it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.22it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.3884 | Train_acc: 90.6250 % | Validation_loss: 1.2355 | Validation_acc: 48.1250 %\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.30it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.35it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.31it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.32it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.29it/s]\n",
      "DEBUG flwr 2024-08-02 10:17:01,407 | server.py:236 | fit_round 18 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2442 | Train_acc: 96.0938 % | Validation_loss: 1.3200 | Validation_acc: 56.2500 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n",
      "Saving round 18 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:17:01,652 | server.py:125 | fit progress: (18, 0.8875994086265564, {'accuracy': 68.95833333333333}, 902.3319285729995)\n",
      "DEBUG flwr 2024-08-02 10:17:01,652 | server.py:173 | evaluate_round 18: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.8875994086265564 / accuracy 68.95833333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 15x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 0] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:17:08,117 | server.py:187 | evaluate_round 18 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:17:08,118 | server.py:222 | fit_round 19: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 5, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6103 | Train_acc: 80.2083 % | Validation_loss: 0.9558 | Validation_acc: 66.2500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.21it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.18it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.34it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.23it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.17it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.2789 | Train_acc: 92.9688 % | Validation_loss: 1.0499 | Validation_acc: 50.0000 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 2, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.47it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.32it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.23it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.37it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.33it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.4206 | Train_acc: 88.2812 % | Validation_loss: 0.8028 | Validation_acc: 69.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.32it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.34it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 6, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.34it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2779 | Train_acc: 95.3125 % | Validation_loss: 0.8403 | Validation_acc: 78.1250 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:05,  1.67it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:04,  1.64it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.23it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.43it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.29it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.42it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.36it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.31it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.40it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.33it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:04<00:02,  1.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.2402 | Train_acc: 97.6562 % | Validation_loss: 1.3255 | Validation_acc: 56.2500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.37it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.37it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.39it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.19it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.27it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.27it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.4235 | Train_acc: 90.6250 % | Validation_loss: 1.2859 | Validation_acc: 68.1250 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.27it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.24it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.26it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 1, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.24it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.25it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.32it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.31it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.3265 | Train_acc: 91.4062 % | Validation_loss: 0.7323 | Validation_acc: 71.2500 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.18it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.38it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.21it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.27it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5011 | Train_acc: 85.9375 % | Validation_loss: 1.5491 | Validation_acc: 66.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.20it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.19it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.24it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.24it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.33it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.52it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.40it/s]\n",
      "DEBUG flwr 2024-08-02 10:17:51,681 | server.py:236 | fit_round 19 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 19 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:17:51,910 | server.py:125 | fit progress: (19, 0.8614274064699808, {'accuracy': 70.83333333333334}, 952.5899080019999)\n",
      "DEBUG flwr 2024-08-02 10:17:51,910 | server.py:173 | evaluate_round 19: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.8614274064699808 / accuracy 70.83333333333334\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.3423 | Train_acc: 89.8438 % | Validation_loss: 1.6212 | Validation_acc: 58.1250 %\u001b[32m [repeated 10x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:17:58,192 | server.py:187 | evaluate_round 19 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-08-02 10:17:58,193 | server.py:222 | fit_round 20: strategy sampled 10 clients (out of 10)\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /opt/conda/envs/fed/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 18x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 4] evaluate, config: {}\u001b[32m [repeated 9x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m   return torch.load(io.BytesIO(b))\u001b[32m [repeated 9x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 7, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.27it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.7553 | Train_acc: 76.5625 % | Validation_loss: 1.2649 | Validation_acc: 69.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:04,  1.52it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:02<00:09,  1.23s/it]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:03,  1.50it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:03<00:07,  1.04s/it]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.08it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:02,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.15it/s]\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.29it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 8, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.2436 | Train_acc: 96.0938 % | Validation_loss: 1.2101 | Validation_acc: 62.8125 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.05it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.12it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:06<00:02,  1.07it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.19it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:07<00:01,  1.09it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:08<00:00,  1.17it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 4, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.11it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.32it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.29it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.3664 | Train_acc: 89.0625 % | Validation_loss: 1.2694 | Validation_acc: 65.0000 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.25it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.25it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.28it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.30it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 1, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.31it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.32it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.30it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.30it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.34it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.31it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2383 | Train_acc: 96.0938 % | Validation_loss: 1.3485 | Validation_acc: 65.0000 %\u001b[32m [repeated 14x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.18it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 9, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.23it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:08,  1.12it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.39it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.32it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.36it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.32it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.38it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.4135 | Train_acc: 91.4062 % | Validation_loss: 0.8798 | Validation_acc: 76.5625 %\u001b[32m [repeated 11x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.36it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 0, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:03,  1.33it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.21it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.32it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.24it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.35it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.29it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:05<00:01,  1.36it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:06<00:00,  1.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 5, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.34it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5780 | Train_acc: 80.9896 % | Validation_loss: 0.9591 | Validation_acc: 66.2500 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:06,  1.16it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:01<00:09,  1.04s/it]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.13it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:07,  1.07it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.23it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:06,  1.15it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:04,  1.22it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.28it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 6, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:03,  1.28it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.22it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.26it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.2477 | Train_acc: 94.5312 % | Validation_loss: 1.0706 | Validation_acc: 50.0000 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.31it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.28it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:08<00:00,  1.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m [Client 2, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.25it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:06,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:00<00:07,  1.28it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.34it/s]\n",
      " 20%|\u001b[34m██        \u001b[0m| 2/10 [00:01<00:05,  1.34it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:02<00:04,  1.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.4257 | Train_acc: 86.7188 % | Validation_loss: 1.2494 | Validation_acc: 65.9375 %\u001b[32m [repeated 12x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:02<00:05,  1.20it/s]\n",
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:03<00:04,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:03<00:05,  1.13it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:04<00:03,  1.18it/s]\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m [Client 3, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|\u001b[34m█████     \u001b[0m| 5/10 [00:04<00:04,  1.18it/s]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.17it/s]\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:05<00:03,  1.16it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.21it/s]\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:05<00:02,  1.22it/s]\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.27it/s]\n",
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:06<00:01,  1.25it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32501)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.2841 | Train_acc: 94.5312 % | Validation_loss: 1.2397 | Validation_acc: 69.6875 %\u001b[32m [repeated 13x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:07<00:00,  1.30it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:07<00:00,  1.30it/s]\n",
      "DEBUG flwr 2024-08-02 10:18:42,076 | server.py:236 | fit_round 20 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 20 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-08-02 10:18:42,303 | server.py:125 | fit progress: (20, 0.8382803698380789, {'accuracy': 70.83333333333334}, 1002.9835592829995)\n",
      "DEBUG flwr 2024-08-02 10:18:42,304 | server.py:173 | evaluate_round 20: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.8382803698380789 / accuracy 70.83333333333334\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m   return torch.load(io.BytesIO(b))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=32502)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2687 | Train_acc: 95.3125 % | Validation_loss: 1.2508 | Validation_acc: 69.6875 %\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32502)\u001b[0m  To get the checkpoint\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m /tmp/ipykernel_32108/1774685687.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\u001b[32m [repeated 17x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m [Client 2] evaluate, config: {}\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=32501)\u001b[0m Updated model\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-08-02 10:18:49,405 | server.py:187 | evaluate_round 20 received 10 results and 0 failures\n",
      "INFO flwr 2024-08-02 10:18:49,406 | server.py:153 | FL finished in 1010.086354606\n",
      "INFO flwr 2024-08-02 10:18:49,408 | app.py:225 | app_fit: losses_distributed [(1, 2.057125371694565), (2, 1.9706361413002014), (3, 1.878628659248352), (4, 1.7780466973781586), (5, 1.6755136847496033), (6, 1.5861166954040526), (7, 1.5017853260040284), (8, 1.423312771320343), (9, 1.3473717540502548), (10, 1.2613644421100616), (11, 1.1784027755260467), (12, 1.1325248509645462), (13, 1.105724686384201), (14, 1.077676810324192), (15, 1.0513047605752945), (16, 1.026830606162548), (17, 1.003830148279667), (18, 0.9833728715777397), (19, 0.9642842590808869), (20, 0.9480832889676094)]\n",
      "INFO flwr 2024-08-02 10:18:49,408 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-08-02 10:18:49,409 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 12.4375), (2, 33.25), (3, 35.8125), (4, 39.375), (5, 43.625), (6, 49.0), (7, 50.4375), (8, 51.5625), (9, 55.46875), (10, 59.0), (11, 59.46875), (12, 61.78125), (13, 63.875), (14, 65.8125), (15, 66.0), (16, 66.15625), (17, 67.625), (18, 67.75), (19, 68.6875), (20, 68.65625)]}\n",
      "INFO flwr 2024-08-02 10:18:49,410 | app.py:228 | app_fit: losses_centralized [(0, 2.0812999407450357), (1, 2.0350462595621743), (2, 1.9479294816652934), (3, 1.8496332168579102), (4, 1.737039307753245), (5, 1.6185004909833272), (6, 1.5172773400942485), (7, 1.4238983194033306), (8, 1.3403326272964478), (9, 1.2623366316159566), (10, 1.1735753019650776), (11, 1.091796596844991), (12, 1.0543761154015858), (13, 1.034390886624654), (14, 1.009142388900121), (15, 0.9797761837641398), (16, 0.9481822649637858), (17, 0.9155133565266927), (18, 0.8875994086265564), (19, 0.8614274064699808), (20, 0.8382803698380789)]\n",
      "INFO flwr 2024-08-02 10:18:49,410 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 14.166666666666666), (1, 14.6875), (2, 35.520833333333336), (3, 37.083333333333336), (4, 42.083333333333336), (5, 44.6875), (6, 52.29166666666667), (7, 53.85416666666667), (8, 56.25), (9, 59.47916666666667), (10, 62.708333333333336), (11, 63.22916666666667), (12, 63.4375), (13, 67.39583333333333), (14, 68.95833333333333), (15, 67.91666666666667), (16, 68.4375), (17, 68.4375), (18, 68.95833333333333), (19, 70.83333333333334), (20, 70.83333333333334)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Time = 1013.9052670001984 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "client_resources = None\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "model_save = model_save\n",
    "path_yaml = yaml_path\n",
    "path_roc = roc_path\n",
    "results_save = save_results\n",
    "path_matrix = matrix_path\n",
    "batch_size = batch_size\n",
    "he = he\n",
    "secret_path = 'secret.pkl'\n",
    "server_path = 'secret.pkl'\n",
    "path_crypted = 'server.pkl'\n",
    "\n",
    "print(\"Start simulation\")\n",
    "start_simulation = time.time()\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=number_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources\n",
    ")\n",
    "print(f\"Simulation Time = {time.time() - start_simulation} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
