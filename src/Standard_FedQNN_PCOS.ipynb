{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images have been successfully moved to the respective label directories.\n",
      "Training set count for class 0: 2067\n",
      "Training set count for class 1: 812\n",
      "Testing set count for class 0: 230\n",
      "Testing set count for class 1: 91\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "import pandas as pd\n",
    "import os, shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "!zenodo_get https://doi.org/10.5281/zenodo.10430727\n",
    "!unzip PCOSGen-train.zip\n",
    "!mv PCOSGen-train/images PCOSGen-train/Training\n",
    "!mkdir data data/PCOS\n",
    "!mv PCOSGen-train/Training data/PCOS\n",
    "!mv PCOSGen-train/class_label.xlsx class_label.xlsx\n",
    "\n",
    "labels_df = pd.read_excel('class_label.xlsx')\n",
    "os.makedirs('data/PCOS/Training/0', exist_ok=True)\n",
    "os.makedirs('data/PCOS/Training/1', exist_ok=True)\n",
    "os.makedirs('data/PCOS/Testing', exist_ok=True)\n",
    "os.makedirs('data/PCOS/Testing/0', exist_ok=True)\n",
    "os.makedirs('data/PCOS/Testing/1', exist_ok=True)\n",
    "\n",
    "for index, row in labels_df.iterrows():\n",
    "    image_path = os.path.join('data/PCOS/Training', row['imagePath'])\n",
    "    destination_dir = os.path.join('data/PCOS/Training', str(row['Healthy']))\n",
    "    destination_path = os.path.join(destination_dir, row['imagePath'])\n",
    "    shutil.move(image_path, destination_path)\n",
    "\n",
    "for label in [0, 1]:\n",
    "    images = os.listdir(f'data/PCOS/Training/{label}')\n",
    "    train_images, test_images = train_test_split(images, test_size=0.1, random_state=42)\n",
    "\n",
    "    for image in test_images:\n",
    "        src_path = f'data/PCOS/Training/{label}/{image}'\n",
    "        dst_path = f'data/PCOS/Testing/{label}/{image}'\n",
    "        shutil.move(src_path, dst_path)    \n",
    "    \n",
    "!rm -rf PCOSGen-train Meta_Data.pdf PCOSGen-train.zip md5sums.txt class_label.xlsx\n",
    "\n",
    "clear_output()\n",
    "print(\"Images have been successfully moved to the respective label directories.\")\n",
    "train_count_0 = len(os.listdir('data/PCOS/Training/0'))\n",
    "train_count_1 = len(os.listdir('data/PCOS/Training/1'))\n",
    "test_count_0 = len(os.listdir('data/PCOS/Testing/0'))\n",
    "test_count_1 = len(os.listdir('data/PCOS/Testing/1'))\n",
    "\n",
    "print(f\"Training set count for class 0: {train_count_0}\")\n",
    "print(f\"Training set count for class 1: {train_count_1}\")\n",
    "print(f\"Testing set count for class 0: {test_count_0}\")\n",
    "print(f\"Testing set count for class 1: {test_count_1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from typing import (\n",
    "    List, Tuple, Dict, Optional, Callable, Union\n",
    ")\n",
    "import tenseal as ts\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    Metrics, EvaluateIns, EvaluateRes, FitIns, FitRes, MetricsAggregationFn, \n",
    "    Scalar, logger, ndarrays_to_parameters_custom, parameters_to_ndarrays_custom,\n",
    "    Parameters, NDArrays\n",
    ")\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.strategy.aggregate import weighted_loss_avg\n",
    "from logging import WARNING\n",
    "import pennylane as qml\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of FHE Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it exists\n"
     ]
    }
   ],
   "source": [
    "def combo_keys(client_path=\"secret.pkl\", server_path=\"server_key.pkl\"):\n",
    "    \"\"\"\n",
    "    To create the public/private keys combination\n",
    "    args:\n",
    "        client_path: path to save the secret key (str)\n",
    "        server_path: path to save the server public key (str)\n",
    "    \"\"\"\n",
    "    context_client = security.context()\n",
    "    security.write_query(client_path, {\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "    security.write_query(server_path, {\"contexte\": context_client.serialize()})\n",
    "\n",
    "    _, context_client = security.read_query(client_path)\n",
    "    _, context_server = security.read_query(server_path)\n",
    "\n",
    "    context_client = ts.context_from(context_client)\n",
    "    context_server = ts.context_from(context_server)\n",
    "    print(\"Is the client context private?\", (\"Yes\" if context_client.is_private() else \"No\"))\n",
    "    print(\"Is the server context private?\", (\"Yes\" if context_server.is_private() else \"No\"))\n",
    "\n",
    "\n",
    "secret_path = \"secret.pkl\"\n",
    "public_path = \"server_key.pkl\"\n",
    "if os.path.exists(secret_path):\n",
    "    print(\"it exists\")\n",
    "    _, context_client = security.read_query(secret_path)\n",
    "\n",
    "else:\n",
    "    combo_keys(client_path=secret_path, server_path=public_path)\n",
    "\n",
    "n_qubits = 4\n",
    "n_layers = 6\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit.torch\", wires=n_qubits)\n",
    "    \n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_net(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits)) \n",
    "    qml.BasicEntanglerLayers(weights,wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple CNN model\n",
    "\n",
    "    Args:\n",
    "        num_classes: An integer indicating the number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 56 * 56, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_qubits),\n",
    "            qml.qnn.TorchLayer(quantum_net, weight_shapes=weight_shapes),\n",
    "            nn.Linear(n_qubits, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FlowerClient class for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader, device, batch_size, save_results, matrix_path, roc_path,\n",
    "                 yaml_path, he, classes, context_client):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.save_results = save_results\n",
    "        self.matrix_path = matrix_path\n",
    "        self.roc_path = roc_path\n",
    "        self.yaml_path = yaml_path\n",
    "        self.he = he\n",
    "        self.classes = classes\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters2(self.net, self.context_client)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        server_round = config['server_round']\n",
    "        local_epochs = config['local_epochs']\n",
    "        lr = float(config[\"learning_rate\"])\n",
    "\n",
    "        print(f'[Client {self.cid}, round {server_round}] fit, config: {config}')\n",
    "\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.Adam(self.net.parameters(), lr=lr)\n",
    "\n",
    "        results = engine.train(self.net, self.trainloader, self.valloader, optimizer=optimizer, loss_fn=criterion,\n",
    "                               epochs=local_epochs, device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            save_graphs(self.save_results, local_epochs, results, f\"_Client {self.cid}\")\n",
    "\n",
    "        return get_parameters2(self.net, self.context_client), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        loss, accuracy, y_pred, y_true, y_proba = engine.test(self.net, self.valloader,\n",
    "                                                              loss_fn=torch.nn.CrossEntropyLoss(), device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            os.makedirs(self.save_results, exist_ok=True)\n",
    "            if self.matrix_path:\n",
    "                save_matrix(y_true, y_pred, self.save_results + self.matrix_path, self.classes)\n",
    "            if self.roc_path:\n",
    "                save_roc(y_true, y_proba, self.save_results + self.roc_path, len(self.classes))\n",
    "\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_common function to set up the Flower client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_common(cid, model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                  batch_size, trainloaders, valloaders, DEVICE, CLASSES,\n",
    "                  he=False, secret_path=\"\", server_path=\"\"):\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    context_client = None\n",
    "    net = Net(num_classes=len(CLASSES)).to(DEVICE)\n",
    "\n",
    "    if he:\n",
    "        print(\"Run with homomorphic encryption\")\n",
    "        if os.path.exists(secret_path):\n",
    "            with open(secret_path, 'rb') as f:\n",
    "                query = pickle.load(f)\n",
    "            context_client = ts.context_from(query[\"contexte\"])\n",
    "        else:\n",
    "            context_client = security.context()\n",
    "            with open(secret_path, 'wb') as f:\n",
    "                encode = pickle.dumps({\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "                f.write(encode)\n",
    "        secret_key = context_client.secret_key()\n",
    "    else:\n",
    "        print(\"Run WITHOUT homomorphic encryption\")\n",
    "\n",
    "    if os.path.exists(model_save):\n",
    "        print(\" To get the checkpoint\")\n",
    "        checkpoint = torch.load(model_save, map_location=DEVICE)['model_state_dict']\n",
    "        if he:\n",
    "            print(\"to decrypt model\")\n",
    "            server_query, server_context = security.read_query(server_path)\n",
    "            server_context = ts.context_from(server_context)\n",
    "            for name in checkpoint:\n",
    "                print(name)\n",
    "                checkpoint[name] = torch.tensor(\n",
    "                    security.deserialized_layer(name, server_query[name], server_context).decrypt(secret_key)\n",
    "                )\n",
    "        net.load_state_dict(checkpoint)\n",
    "\n",
    "    return FlowerClient(cid, net, trainloader, valloader, device=DEVICE, batch_size=batch_size,\n",
    "                        matrix_path=path_matrix, roc_path=path_roc, save_results=results_save, yaml_path=path_yaml,\n",
    "                        he=he, context_client=context_client, classes=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def evaluate2(server_round: int, parameters: NDArrays,\n",
    "              config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    set_parameters(central, parameters)\n",
    "    loss, accuracy, y_pred, y_true, y_proba = engine.test(central, testloader, loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                          device=DEVICE)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def get_on_fit_config_fn(epoch=2, lr=0.001, batch_size=32) -> Callable[[int], Dict[str, str]]:\n",
    "    def fit_config(server_round: int) -> Dict[str, str]:\n",
    "        config = {\n",
    "            \"learning_rate\": str(lr),\n",
    "            \"batch_size\": str(batch_size),\n",
    "            \"server_round\": server_round,\n",
    "            \"local_epochs\": epoch\n",
    "        }\n",
    "        return config\n",
    "    return fit_config\n",
    "\n",
    "def aggreg_fit_checkpoint(server_round, aggregated_parameters, central_model, path_checkpoint,\n",
    "                          context_client=None, server_path=\"\"):\n",
    "    if aggregated_parameters is not None:\n",
    "        print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "        aggregated_ndarrays: List[np.ndarray] = parameters_to_ndarrays_custom(aggregated_parameters, context_client)\n",
    "        if context_client:   \n",
    "            server_response = {\"contexte\": server_context.serialize()}\n",
    "            for i, key in enumerate(central_model.state_dict().keys()):\n",
    "                try:\n",
    "                    server_response[key] = aggregated_ndarrays[i].serialize()\n",
    "                except:\n",
    "                    server_response[key] = aggregated_ndarrays[i]\n",
    "            security.write_query(server_path, server_response)\n",
    "        else:\n",
    "            params_dict = zip(central_model.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            central_model.load_state_dict(state_dict, strict=True)\n",
    "            if path_checkpoint:\n",
    "                torch.save({\n",
    "                    'model_state_dict': central_model.state_dict(),\n",
    "                }, path_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FedCustom strategy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Strategy from scratch with the same sampling of the clients as it is in FedAvg\n",
    "# and then change the configuration dictionary\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "            self,\n",
    "            fraction_fit: float = 1.0,\n",
    "            fraction_evaluate: float = 1.0,\n",
    "            min_fit_clients: int = 2,\n",
    "            min_evaluate_clients: int = 2,\n",
    "            min_available_clients: int = 2,\n",
    "            evaluate_fn: Optional[\n",
    "                    Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
    "                ] = None,\n",
    "            on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            accept_failures: bool = True,\n",
    "            initial_parameters: Optional[Parameters] = None,\n",
    "            fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            context_client=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn,\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        return f\"FedCustom (accept_failures={self.accept_failures})\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        initial_parameters = self.initial_parameters\n",
    "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
    "        return initial_parameters\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        # Create custom configs\n",
    "        n_clients = len(clients)\n",
    "        half_clients = n_clients // 2\n",
    "        # Custom fit config function provided\n",
    "        standard_lr = lr\n",
    "        higher_lr = 0.003\n",
    "        config = {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "        if self.on_fit_config_fn is not None:\n",
    "            # Custom fit config function provided\n",
    "            config = self.on_fit_config_fn(server_round)\n",
    "\n",
    "        # fit_ins = FitIns(parameters, config)\n",
    "        # Return client/config pairs\n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            config[\"learning_rate\"] = standard_lr if idx < half_clients else higher_lr\n",
    "            \"\"\"\n",
    "            Each pair of (ClientProxy, FitRes) constitutes \n",
    "            a successful update from one of the previously selected clients.\n",
    "            \"\"\"\n",
    "            fit_configurations.append(\n",
    "                (\n",
    "                    client,\n",
    "                    FitIns(\n",
    "                        parameters,\n",
    "                        config\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        # Successful updates from the previously selected and configured clients\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average. (each round)\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Convert results parameters --> array matrix\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays_custom(fit_res.parameters, self.context_client), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        # Aggregate parameters using weighted average between the clients and convert back to parameters object (bytes)\n",
    "        parameters_aggregated = ndarrays_to_parameters_custom(aggregate_custom(weights_results))\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "\n",
    "        elif server_round == 1:  # Only log this warning once\n",
    "            logger.log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "\n",
    "        # Same function as SaveModelStrategy(fl.server.strategy.FedAvg)\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        aggreg_fit_checkpoint(server_round, parameters_aggregated, central, model_save,\n",
    "                              self.context_client, path_crypted)\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        # Do not configure federated evaluation if fraction eval is 0.\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "\n",
    "        # Parameters and config\n",
    "        config = {}  # {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        # Each pair of (ClientProxy, FitRes) constitutes a successful update from one of the previously selected clients\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Aggregate loss\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.evaluate_metrics_aggregation_fn:\n",
    "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
    "\n",
    "        # Only log this warning once\n",
    "        elif server_round == 1:\n",
    "            logger.log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
    "\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if self.evaluate_fn is None:\n",
    "            # Let's assume we won't perform the global model evaluation on the server side.\n",
    "            return None\n",
    "\n",
    "        # if we have a global model evaluation on the server side :\n",
    "        parameters_ndarrays = parameters_to_ndarrays_custom(parameters, self.context_client)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "\n",
    "        # if you haven't results\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the federated learning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your variables directly\n",
    "he = False\n",
    "data_path = 'data/'\n",
    "dataset = 'PCOS'\n",
    "yaml_path = './results/FL/results.yml'\n",
    "seed = 0\n",
    "num_workers = 0\n",
    "max_epochs = 10\n",
    "batch_size = 32\n",
    "splitter = 10\n",
    "device = 'gpu'\n",
    "number_clients = 10\n",
    "save_results = 'results/FL/'\n",
    "matrix_path = 'confusion_matrix.png'\n",
    "roc_path = 'roc.png'\n",
    "model_save = 'PCOS_fl.pt'\n",
    "min_fit_clients = 10\n",
    "min_avail_clients = 10\n",
    "min_eval_clients = 10\n",
    "rounds = 20\n",
    "frac_fit = 1.0\n",
    "frac_eval = 0.5\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_context = None\n",
    "DEVICE = torch.device(choice_device(device))\n",
    "CLASSES = classes_string(dataset)\n",
    "central = Net(num_classes=len(CLASSES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FedCustom(\n",
    "    fraction_fit=frac_fit,\n",
    "    fraction_evaluate=frac_eval,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_eval_clients if min_eval_clients else number_clients // 2,\n",
    "    min_available_clients=min_avail_clients,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    initial_parameters=ndarrays_to_parameters_custom(get_parameters2(central)),\n",
    "    evaluate_fn=None if he else evaluate2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(epoch=max_epochs, batch_size=batch_size),\n",
    "    context_client=server_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCOS\n",
      "The training set is created for the classes : ['0', '1']\n"
     ]
    }
   ],
   "source": [
    "trainloaders, valloaders, testloader = data_setup.load_datasets(num_clients=number_clients,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                resize=224,\n",
    "                                                                seed=seed,\n",
    "                                                                num_workers=num_workers,\n",
    "                                                                splitter=splitter,\n",
    "                                                                dataset=dataset,  # Use the specified dataset\n",
    "                                                                data_path=data_path,\n",
    "                                                                data_path_val=None)  # Use the same path for validation data\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    return client_common(cid,\n",
    "                         model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                         batch_size, trainloaders, valloaders, DEVICE, CLASSES, he, secret_path, server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_fn function and set up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:16:03,632 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=20, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.5.0\n",
      "numpy 1.26.4\n",
      "torch 2.1.2\n",
      "torchvision 0.16.2\n",
      "Training on cuda:0\n",
      "Start simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-24 04:16:07,933\tINFO worker.py:1724 -- Started a local Ray instance.\n",
      "INFO flwr 2024-07-24 04:16:09,262 | app.py:179 | Flower VCE: Ray initialized with resources: {'GPU': 2.0, 'memory': 17859511911.0, 'object_store_memory': 8929755955.0, 'accelerator_type:T4': 1.0, 'CPU': 4.0, 'node:__internal_head__': 1.0, 'node:172.19.2.2': 1.0}\n",
      "INFO flwr 2024-07-24 04:16:09,264 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-07-24 04:16:09,265 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-07-24 04:16:09,270 | server.py:91 | Evaluating initial parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:16:11,463 | server.py:94 | initial parameters (loss, other metrics): 0.6918965632265265, {'accuracy': 64.77272727272727}\n",
      "INFO flwr 2024-07-24 04:16:11,464 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-07-24 04:16:11,465 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.6918965632265265 / accuracy 64.77272727272727\n",
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m [Client 3, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6883 | Train_acc: 60.8796 % | Validation_loss: 0.6778 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:22,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=409)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=409)\u001b[0m [Client 6, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=409)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=409)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6465 | Train_acc: 73.2639 % | Validation_loss: 0.6404 | Validation_acc: 75.0000 %\u001b[32m [repeated 7x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.80s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6419 | Train_acc: 71.9907 % | Validation_loss: 0.6719 | Validation_acc: 60.7143 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.76s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=407)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6103 | Train_acc: 75.3472 % | Validation_loss: 0.6573 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=486)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=409)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=409)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6255 | Train_acc: 70.6019 % | Validation_loss: 0.6035 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=486)\u001b[0m [Client 0, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=486)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=486)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6856 | Train_acc: 58.4491 % | Validation_loss: 0.6894 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m [Client 1, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6523 | Train_acc: 71.9907 % | Validation_loss: 0.6639 | Validation_acc: 67.8571 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.73s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6241 | Train_acc: 74.4213 % | Validation_loss: 0.6312 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=486)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6180 | Train_acc: 71.0648 % | Validation_loss: 0.6310 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=563)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=488)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=563)\u001b[0m [Client 4, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=563)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=563)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6792 | Train_acc: 64.1204 % | Validation_loss: 0.6741 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m [Client 5, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6572 | Train_acc: 70.2546 % | Validation_loss: 0.6969 | Validation_acc: 57.1429 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.76s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6574 | Train_acc: 66.8981 % | Validation_loss: 0.6865 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=563)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6212 | Train_acc: 73.6111 % | Validation_loss: 0.6881 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=588)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m [Client 9, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6815 | Train_acc: 61.2058 % | Validation_loss: 0.6728 | Validation_acc: 62.0690 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=662)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=662)\u001b[0m [Client 7, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=662)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6657 | Train_acc: 65.3725 % | Validation_loss: 0.6451 | Validation_acc: 72.4138 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6446 | Train_acc: 66.7929 % | Validation_loss: 0.6176 | Validation_acc: 72.4138 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=637)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6337 | Train_acc: 66.7929 % | Validation_loss: 0.5988 | Validation_acc: 72.4138 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=662)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=662)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2689 | Train_acc: 97.9167 % | Validation_loss: 0.6239 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m [Client 8, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6876 | Train_acc: 54.5139 % | Validation_loss: 0.6749 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=713)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=713)\u001b[0m [Client 2, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=713)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6475 | Train_acc: 75.4630 % | Validation_loss: 0.6430 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6045 | Train_acc: 78.8194 % | Validation_loss: 0.6337 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=711)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5652 | Train_acc: 78.8194 % | Validation_loss: 0.6061 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-07-24 04:18:36,611 | server.py:236 | fit_round 1 received 10 results and 0 failures\n",
      "WARNING flwr 2024-07-24 04:18:37,229 | 3890383987.py:131 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:18:38,571 | server.py:125 | fit progress: (1, 0.6523008807138964, {'accuracy': 65.3409090909091}, 147.106389826)\n",
      "DEBUG flwr 2024-07-24 04:18:38,572 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.6523008807138964 / accuracy 65.3409090909091\n",
      "\u001b[36m(launch_and_evaluate pid=794)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=794)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=713)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=713)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5592 | Train_acc: 68.5185 % | Validation_loss: 0.5628 | Validation_acc: 78.5714 %\n",
      "\u001b[36m(launch_and_evaluate pid=794)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=794)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=865)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=865)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=795)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=795)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=865)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=865)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=937)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=937)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=867)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=867)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=937)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=937)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1007)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1007)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=935)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=935)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1009)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1009)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1078)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1078)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1007)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1007)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1078)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1078)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:19:38,392 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:19:38,393 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1080)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1080)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m [Client 7, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5912 | Train_acc: 79.1667 % | Validation_loss: 0.6162 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m [Client 2, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6020 | Train_acc: 72.4537 % | Validation_loss: 0.6129 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.71s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6044 | Train_acc: 71.5278 % | Validation_loss: 0.5532 | Validation_acc: 78.5714 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1159)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6519 | Train_acc: 64.8148 % | Validation_loss: 0.5440 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1158)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m [Client 5, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1233)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1233)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.6252 | Train_acc: 70.2546 % | Validation_loss: 0.7247 | Validation_acc: 53.5714 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1233)\u001b[0m [Client 8, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1233)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.6144 | Train_acc: 70.2546 % | Validation_loss: 0.7264 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.6196 | Train_acc: 70.2546 % | Validation_loss: 0.7205 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1231)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1233)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5663 | Train_acc: 75.4630 % | Validation_loss: 0.5727 | Validation_acc: 75.0000 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1233)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m [Client 3, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.79s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.6385 | Train_acc: 68.6343 % | Validation_loss: 0.6894 | Validation_acc: 60.7143 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m [Client 6, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.6030 | Train_acc: 71.9907 % | Validation_loss: 0.6809 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.5850 | Train_acc: 67.2454 % | Validation_loss: 0.5389 | Validation_acc: 75.0000 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1305)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5474 | Train_acc: 67.2454 % | Validation_loss: 0.5257 | Validation_acc: 75.0000 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1307)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m [Client 9, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.88s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1381)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1381)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.6433 | Train_acc: 66.1301 % | Validation_loss: 0.6105 | Validation_acc: 72.4138 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1381)\u001b[0m [Client 1, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1381)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.6251 | Train_acc: 67.4558 % | Validation_loss: 0.6049 | Validation_acc: 72.4138 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.6375 | Train_acc: 66.7929 % | Validation_loss: 0.5916 | Validation_acc: 72.4138 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1379)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1381)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6213 | Train_acc: 67.7083 % | Validation_loss: 0.6195 | Validation_acc: 67.8571 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1381)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m [Client 4, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.5935 | Train_acc: 70.2546 % | Validation_loss: 0.6735 | Validation_acc: 60.7143 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m [Client 0, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.5334 | Train_acc: 70.2546 % | Validation_loss: 0.6943 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.5911 | Train_acc: 72.6852 % | Validation_loss: 0.6444 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.67s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1455)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:22:04,018 | server.py:236 | fit_round 2 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 2 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:22:06,029 | server.py:125 | fit progress: (2, 0.654758870601654, {'accuracy': 65.3409090909091}, 354.56465604299996)\n",
      "DEBUG flwr 2024-07-24 04:22:06,030 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.654758870601654 / accuracy 65.3409090909091\n",
      "\u001b[36m(launch_and_evaluate pid=1536)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=1536)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5655 | Train_acc: 76.0417 % | Validation_loss: 0.6444 | Validation_acc: 64.2857 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1453)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=1536)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1536)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1607)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1607)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1537)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1537)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1607)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1607)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1677)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1677)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1609)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1609)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1677)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1677)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1749)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1749)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1679)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1679)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1749)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1749)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1818)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1818)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1747)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1747)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=1818)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1818)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:23:06,409 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:23:06,410 | server.py:222 | fit_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1898)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1898)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=1820)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=1820)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m [Client 3, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1898)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6000 | Train_acc: 71.9907 % | Validation_loss: 0.6801 | Validation_acc: 60.7143 %\n",
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1898)\u001b[0m [Client 7, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.86s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5985 | Train_acc: 71.9907 % | Validation_loss: 0.6879 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6245 | Train_acc: 68.6343 % | Validation_loss: 0.6910 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.70s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1897)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1898)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5211 | Train_acc: 79.1667 % | Validation_loss: 0.5967 | Validation_acc: 71.4286 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1898)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m [Client 0, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6098 | Train_acc: 70.2546 % | Validation_loss: 0.6824 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1972)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=1972)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1972)\u001b[0m [Client 9, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=1972)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6379 | Train_acc: 66.8981 % | Validation_loss: 0.6969 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6096 | Train_acc: 70.2546 % | Validation_loss: 0.7061 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=1970)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=1972)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.3321 | Train_acc: 93.8447 % | Validation_loss: 0.6051 | Validation_acc: 72.4138 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=1972)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m [Client 5, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6660 | Train_acc: 63.5417 % | Validation_loss: 0.7323 | Validation_acc: 53.5714 %\n",
      "\u001b[36m(launch_and_fit pid=2046)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2046)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2046)\u001b[0m [Client 8, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2046)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.76s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5938 | Train_acc: 70.2546 % | Validation_loss: 0.7857 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.5328 | Train_acc: 70.2546 % | Validation_loss: 0.7838 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2044)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2046)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5605 | Train_acc: 75.4630 % | Validation_loss: 0.5593 | Validation_acc: 75.0000 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2118)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2118)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2046)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.80s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2118)\u001b[0m [Client 6, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2118)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2118)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5754 | Train_acc: 73.9583 % | Validation_loss: 0.5691 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.77s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m [Client 4, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5954 | Train_acc: 72.6852 % | Validation_loss: 0.6607 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6209 | Train_acc: 69.3287 % | Validation_loss: 0.6525 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2118)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5856 | Train_acc: 72.6852 % | Validation_loss: 0.6539 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2143)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m [Client 2, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6064 | Train_acc: 71.5278 % | Validation_loss: 0.5475 | Validation_acc: 78.5714 %\n",
      "\u001b[36m(launch_and_fit pid=2194)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2194)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2194)\u001b[0m [Client 1, round 3] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 3, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2194)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6505 | Train_acc: 64.8148 % | Validation_loss: 0.5493 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6275 | Train_acc: 68.1713 % | Validation_loss: 0.5523 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2192)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6303 | Train_acc: 68.1713 % | Validation_loss: 0.5416 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:25:32,433 | server.py:236 | fit_round 3 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 3 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:25:34,442 | server.py:125 | fit progress: (3, 0.6380183290351521, {'accuracy': 65.3409090909091}, 562.977565742)\n",
      "DEBUG flwr 2024-07-24 04:25:34,443 | server.py:173 | evaluate_round 3: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.6380183290351521 / accuracy 65.3409090909091\n",
      "\u001b[36m(launch_and_evaluate pid=2275)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=2275)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2194)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2194)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5290 | Train_acc: 77.7778 % | Validation_loss: 0.6479 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_evaluate pid=2275)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2275)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2346)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2346)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2276)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2276)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2346)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2346)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2416)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2416)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2348)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2348)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2416)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2416)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2487)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2487)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2418)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2418)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2487)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2487)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2559)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2559)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2488)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2488)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=2557)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2559)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:26:34,731 | server.py:187 | evaluate_round 3 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:26:34,732 | server.py:222 | fit_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=2559)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=2557)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m [Client 9, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6266 | Train_acc: 68.1187 % | Validation_loss: 0.5918 | Validation_acc: 72.4138 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.84s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m [Client 6, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6170 | Train_acc: 68.1187 % | Validation_loss: 0.6040 | Validation_acc: 72.4138 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.6051 | Train_acc: 70.6019 % | Validation_loss: 0.5663 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2636)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6599 | Train_acc: 63.8889 % | Validation_loss: 0.5591 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2637)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2417 | Train_acc: 99.6528 % | Validation_loss: 0.5981 | Validation_acc: 68.9655 %\n",
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m [Client 5, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6037 | Train_acc: 70.2546 % | Validation_loss: 0.7423 | Validation_acc: 53.5714 %\n",
      "\u001b[36m(launch_and_fit pid=2711)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2711)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2711)\u001b[0m [Client 4, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2711)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5594 | Train_acc: 70.2546 % | Validation_loss: 0.8149 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.4092 | Train_acc: 70.2546 % | Validation_loss: 0.8381 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2709)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2342 | Train_acc: 97.2222 % | Validation_loss: 0.9358 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2711)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2711)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4593 | Train_acc: 72.6852 % | Validation_loss: 0.6355 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m [Client 2, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6519 | Train_acc: 64.8148 % | Validation_loss: 0.5437 | Validation_acc: 78.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.79s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2785)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2785)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2785)\u001b[0m [Client 7, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2785)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.6282 | Train_acc: 64.8148 % | Validation_loss: 0.5176 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.4124 | Train_acc: 69.5602 % | Validation_loss: 0.5802 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2783)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.2428 | Train_acc: 97.9167 % | Validation_loss: 0.6111 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2785)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2785)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.5582 | Train_acc: 75.8102 % | Validation_loss: 0.6127 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m [Client 8, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5962 | Train_acc: 72.1065 % | Validation_loss: 0.5673 | Validation_acc: 75.0000 %\n",
      "\u001b[36m(launch_and_fit pid=2859)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2859)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2859)\u001b[0m [Client 0, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2859)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5953 | Train_acc: 72.1065 % | Validation_loss: 0.5625 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.70s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.5394 | Train_acc: 75.4630 % | Validation_loss: 0.5639 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2857)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.3678 | Train_acc: 78.8194 % | Validation_loss: 0.6014 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2859)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2859)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4726 | Train_acc: 70.2546 % | Validation_loss: 0.7088 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m [Client 3, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5928 | Train_acc: 71.9907 % | Validation_loss: 0.6881 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2956)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=2956)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2956)\u001b[0m [Client 1, round 4] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 4, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=2956)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5924 | Train_acc: 71.9907 % | Validation_loss: 0.7018 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.5394 | Train_acc: 71.9907 % | Validation_loss: 0.7212 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2931)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.3244 | Train_acc: 85.0694 % | Validation_loss: 0.6915 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:29:01,555 | server.py:236 | fit_round 4 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 4 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:29:03,592 | server.py:125 | fit progress: (4, 0.6458223245360635, {'accuracy': 65.3409090909091}, 772.1273135280001)\n",
      "DEBUG flwr 2024-07-24 04:29:03,593 | server.py:173 | evaluate_round 4: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.6458223245360635 / accuracy 65.3409090909091\n",
      "\u001b[36m(launch_and_evaluate pid=3016)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=3016)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=2956)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=2956)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.4045 | Train_acc: 77.7778 % | Validation_loss: 0.6610 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_evaluate pid=3016)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3016)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3086)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3086)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3015)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3015)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3086)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3086)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3156)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3156)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3088)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3088)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3156)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3156)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3226)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3226)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3158)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3158)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3226)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3226)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3298)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3298)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3228)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3228)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3298)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3298)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:30:03,760 | server.py:187 | evaluate_round 4 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:30:03,761 | server.py:222 | fit_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3375)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=3375)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3296)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3296)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m [Client 3, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5688 | Train_acc: 75.3472 % | Validation_loss: 0.7642 | Validation_acc: 60.7143 %\n",
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3375)\u001b[0m [Client 5, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3375)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.88s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.3368 | Train_acc: 87.1528 % | Validation_loss: 0.6728 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.1866 | Train_acc: 98.9583 % | Validation_loss: 0.6839 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3376)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0844 | Train_acc: 100.0000 % | Validation_loss: 0.8754 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3375)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3375)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0893 | Train_acc: 100.0000 % | Validation_loss: 1.1502 | Validation_acc: 46.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m [Client 0, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6102 | Train_acc: 70.2546 % | Validation_loss: 0.7130 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3450)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3450)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3450)\u001b[0m [Client 7, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3450)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.4251 | Train_acc: 70.9491 % | Validation_loss: 0.7110 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.79s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.2012 | Train_acc: 98.6111 % | Validation_loss: 0.8862 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3448)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.1021 | Train_acc: 98.6111 % | Validation_loss: 0.9056 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3450)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3450)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.3282 | Train_acc: 79.1667 % | Validation_loss: 0.6127 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.81s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m [Client 4, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5377 | Train_acc: 76.0417 % | Validation_loss: 0.7255 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.87s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3547)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3547)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3547)\u001b[0m [Client 9, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3547)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.5862 | Train_acc: 72.6852 % | Validation_loss: 0.6699 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.81s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.5788 | Train_acc: 72.6852 % | Validation_loss: 0.6823 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3522)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.6028 | Train_acc: 72.6852 % | Validation_loss: 0.6405 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3547)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3547)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0647 | Train_acc: 100.0000 % | Validation_loss: 0.6788 | Validation_acc: 65.5172 %\n",
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m [Client 8, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.83s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5844 | Train_acc: 75.4630 % | Validation_loss: 0.5593 | Validation_acc: 75.0000 %\n",
      "\u001b[36m(launch_and_fit pid=3621)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3621)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.83s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3621)\u001b[0m [Client 1, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3621)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.4252 | Train_acc: 75.4630 % | Validation_loss: 0.5427 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.84s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.2311 | Train_acc: 94.2130 % | Validation_loss: 0.6260 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3596)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.1243 | Train_acc: 97.5694 % | Validation_loss: 0.6969 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=3670)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3670)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3621)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3621)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.1362 | Train_acc: 98.2639 % | Validation_loss: 0.6941 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3670)\u001b[0m [Client 2, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3670)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3670)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.6091 | Train_acc: 68.1713 % | Validation_loss: 0.5202 | Validation_acc: 78.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.78s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m [Client 6, round 5] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 5, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.3082 | Train_acc: 95.4861 % | Validation_loss: 0.5468 | Validation_acc: 71.4286 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.1626 | Train_acc: 95.6019 % | Validation_loss: 0.6448 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=3670)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0810 | Train_acc: 99.6528 % | Validation_loss: 0.7374 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:32:31,474 | server.py:236 | fit_round 5 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 5 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:32:33,489 | server.py:125 | fit progress: (5, 0.6118300340392373, {'accuracy': 66.19318181818183}, 982.024190163)\n",
      "DEBUG flwr 2024-07-24 04:32:33,490 | server.py:173 | evaluate_round 5: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.6118300340392373 / accuracy 66.19318181818183\n",
      "\u001b[36m(launch_and_evaluate pid=3753)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=3753)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=3672)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=3753)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3753)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3824)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3824)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3754)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3754)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3824)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3824)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3894)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3894)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3826)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3826)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3894)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3894)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3966)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3966)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3896)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3896)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=3964)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3964)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4034)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4034)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=3966)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=3966)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4034)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4034)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:33:33,576 | server.py:187 | evaluate_round 5 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:33:33,577 | server.py:222 | fit_round 6: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4036)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4036)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m [Client 6, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5832 | Train_acc: 75.8102 % | Validation_loss: 0.4811 | Validation_acc: 78.5714 %\n",
      "\u001b[36m(launch_and_fit pid=4115)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4115)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4115)\u001b[0m [Client 2, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4115)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.84s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.1119 | Train_acc: 98.6111 % | Validation_loss: 0.7306 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0611 | Train_acc: 99.6528 % | Validation_loss: 0.8098 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4114)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0449 | Train_acc: 99.6528 % | Validation_loss: 0.9524 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4189)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4189)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4115)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4115)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0220 | Train_acc: 100.0000 % | Validation_loss: 0.8023 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=4189)\u001b[0m [Client 8, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5000 | Train_acc: 77.7778 % | Validation_loss: 0.8096 | Validation_acc: 53.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.76s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m [Client 0, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4189)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 0.1033 | Train_acc: 98.6111 % | Validation_loss: 0.8376 | Validation_acc: 57.1429 %\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0474 | Train_acc: 99.3056 % | Validation_loss: 0.8850 | Validation_acc: 57.1429 %\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4187)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4189)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0375 | Train_acc: 99.6528 % | Validation_loss: 0.9555 | Validation_acc: 60.7143 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4189)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m [Client 5, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.1572 | Train_acc: 97.5694 % | Validation_loss: 1.0754 | Validation_acc: 50.0000 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m [Client 4, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0656 | Train_acc: 98.9583 % | Validation_loss: 1.1235 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0315 | Train_acc: 100.0000 % | Validation_loss: 0.8389 | Validation_acc: 60.7143 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4261)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0247 | Train_acc: 100.0000 % | Validation_loss: 0.8514 | Validation_acc: 64.2857 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4263)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m [Client 9, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4337)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4337)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.1082 | Train_acc: 98.6111 % | Validation_loss: 0.7256 | Validation_acc: 68.9655 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4337)\u001b[0m [Client 3, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4337)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0412 | Train_acc: 99.6528 % | Validation_loss: 0.7441 | Validation_acc: 68.9655 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0244 | Train_acc: 100.0000 % | Validation_loss: 0.8319 | Validation_acc: 62.0690 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4337)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0200 | Train_acc: 100.0000 % | Validation_loss: 0.8292 | Validation_acc: 65.5172 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4335)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m [Client 1, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.85s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.1474 | Train_acc: 97.9167 % | Validation_loss: 0.7939 | Validation_acc: 64.2857 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m [Client 7, round 6] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 6, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0513 | Train_acc: 100.0000 % | Validation_loss: 0.7957 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0426 | Train_acc: 100.0000 % | Validation_loss: 0.8367 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4411)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:35:59,288 | server.py:236 | fit_round 6 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 6 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:36:01,279 | server.py:125 | fit progress: (6, 0.6617710529403253, {'accuracy': 63.92045454545454}, 1189.8143932409998)\n",
      "DEBUG flwr 2024-07-24 04:36:01,280 | server.py:173 | evaluate_round 6: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.6617710529403253 / accuracy 63.92045454545454\n",
      "\u001b[36m(launch_and_evaluate pid=4492)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=4492)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0314 | Train_acc: 100.0000 % | Validation_loss: 0.9729 | Validation_acc: 57.1429 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4409)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=4492)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4492)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4564)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4564)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4493)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4493)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4564)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4564)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4632)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4632)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4563)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4563)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4632)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4632)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4702)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4702)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4634)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4634)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4702)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4702)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4772)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4772)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4704)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4704)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=4772)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4772)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:37:01,374 | server.py:187 | evaluate_round 6 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:37:01,375 | server.py:222 | fit_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=4774)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=4774)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m [Client 4, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.5770 | Train_acc: 69.4444 % | Validation_loss: 0.5706 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.83s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4852)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4852)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4852)\u001b[0m [Client 8, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4852)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0718 | Train_acc: 98.6111 % | Validation_loss: 0.6867 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0253 | Train_acc: 99.6528 % | Validation_loss: 0.7312 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4851)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0140 | Train_acc: 100.0000 % | Validation_loss: 0.7600 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4925)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4925)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4852)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=4852)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0097 | Train_acc: 100.0000 % | Validation_loss: 1.0048 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=4925)\u001b[0m [Client 3, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4925)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4925)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2654 | Train_acc: 89.2361 % | Validation_loss: 0.6547 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m [Client 0, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.76s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0392 | Train_acc: 99.6528 % | Validation_loss: 0.9069 | Validation_acc: 60.7143 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0221 | Train_acc: 99.6528 % | Validation_loss: 0.8919 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=4925)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5000)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5000)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0279 | Train_acc: 99.3056 % | Validation_loss: 0.9068 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=4927)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5000)\u001b[0m [Client 9, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5000)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.0971 | Train_acc: 97.2222 % | Validation_loss: 0.8156 | Validation_acc: 67.8571 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.84s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m [Client 6, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 0.0202 | Train_acc: 100.0000 % | Validation_loss: 1.0376 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.0097 | Train_acc: 100.0000 % | Validation_loss: 1.1470 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5000)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5074)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5074)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0068 | Train_acc: 100.0000 % | Validation_loss: 1.2061 | Validation_acc: 64.2857 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5002)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5074)\u001b[0m [Client 7, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5074)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.1555 | Train_acc: 95.1389 % | Validation_loss: 0.9869 | Validation_acc: 60.7143 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m [Client 1, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.86s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 0.0296 | Train_acc: 100.0000 % | Validation_loss: 1.0509 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.0114 | Train_acc: 100.0000 % | Validation_loss: 1.0217 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5074)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5148)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5148)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0079 | Train_acc: 100.0000 % | Validation_loss: 1.0812 | Validation_acc: 67.8571 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5076)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5148)\u001b[0m [Client 2, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5148)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.2013 | Train_acc: 90.3935 % | Validation_loss: 0.9414 | Validation_acc: 57.1429 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.91s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m [Client 5, round 7] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 7, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 0.0458 | Train_acc: 99.3056 % | Validation_loss: 1.3366 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.0276 | Train_acc: 99.6528 % | Validation_loss: 1.4368 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5148)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:39:28,278 | server.py:236 | fit_round 7 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 7 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:39:30,315 | server.py:125 | fit progress: (7, 0.7338515366004272, {'accuracy': 65.625}, 1398.849728384)\n",
      "DEBUG flwr 2024-07-24 04:39:30,316 | server.py:173 | evaluate_round 7: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.7338515366004272 / accuracy 65.625\n",
      "\u001b[36m(launch_and_evaluate pid=5231)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=5231)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0353 | Train_acc: 99.3056 % | Validation_loss: 1.4371 | Validation_acc: 60.7143 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5150)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=5231)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5231)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5302)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5302)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5232)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5232)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5302)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5302)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5374)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5374)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5304)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5304)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5374)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5374)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5443)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5443)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5372)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5372)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5443)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5443)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5514)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5514)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5445)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5445)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=5514)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5516)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:40:30,323 | server.py:187 | evaluate_round 7 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:40:30,324 | server.py:222 | fit_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5516)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5514)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m [Client 4, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.3504 | Train_acc: 83.4491 % | Validation_loss: 0.6760 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=5594)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5594)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5594)\u001b[0m [Client 6, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5594)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0207 | Train_acc: 99.3056 % | Validation_loss: 0.7960 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0134 | Train_acc: 99.6528 % | Validation_loss: 0.8782 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5593)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5594)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0055 | Train_acc: 100.0000 % | Validation_loss: 1.1526 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5594)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m [Client 0, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.4087 | Train_acc: 85.4167 % | Validation_loss: 1.1792 | Validation_acc: 50.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.83s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5668)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5668)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5668)\u001b[0m [Client 8, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5668)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0978 | Train_acc: 91.5509 % | Validation_loss: 1.3690 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.1789 | Train_acc: 93.5185 % | Validation_loss: 0.9607 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5666)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0467 | Train_acc: 98.6111 % | Validation_loss: 1.0211 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5668)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5668)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0172 | Train_acc: 99.6528 % | Validation_loss: 1.1916 | Validation_acc: 50.0000 %\n",
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m [Client 5, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.80s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.3499 | Train_acc: 83.4491 % | Validation_loss: 1.6395 | Validation_acc: 50.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5742)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5742)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5742)\u001b[0m [Client 9, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5742)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0342 | Train_acc: 99.3056 % | Validation_loss: 1.3879 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0072 | Train_acc: 100.0000 % | Validation_loss: 1.7506 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5740)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0050 | Train_acc: 100.0000 % | Validation_loss: 1.8520 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5742)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5742)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0037 | Train_acc: 100.0000 % | Validation_loss: 1.1404 | Validation_acc: 65.5172 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.81s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m [Client 2, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.3143 | Train_acc: 87.1528 % | Validation_loss: 0.6707 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.84s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5816)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5816)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5816)\u001b[0m [Client 3, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5816)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0244 | Train_acc: 99.6528 % | Validation_loss: 0.6201 | Validation_acc: 82.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0081 | Train_acc: 100.0000 % | Validation_loss: 0.7509 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5814)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0044 | Train_acc: 100.0000 % | Validation_loss: 0.7578 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5816)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5816)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0037 | Train_acc: 100.0000 % | Validation_loss: 1.1822 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m [Client 7, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.3119 | Train_acc: 87.8472 % | Validation_loss: 1.2995 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=5890)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=5890)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5890)\u001b[0m [Client 1, round 8] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 8, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=5890)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0180 | Train_acc: 100.0000 % | Validation_loss: 1.0550 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0053 | Train_acc: 100.0000 % | Validation_loss: 1.2436 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5888)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0135 | Train_acc: 100.0000 % | Validation_loss: 1.1340 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:42:57,174 | server.py:236 | fit_round 8 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 8 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:42:59,186 | server.py:125 | fit progress: (8, 0.7946386493065141, {'accuracy': 65.9090909090909}, 1607.720760031)\n",
      "DEBUG flwr 2024-07-24 04:42:59,187 | server.py:173 | evaluate_round 8: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.7946386493065141 / accuracy 65.9090909090909\n",
      "\u001b[36m(launch_and_evaluate pid=5971)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=5971)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=5890)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=5890)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0054 | Train_acc: 100.0000 % | Validation_loss: 1.1734 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_evaluate pid=5971)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5971)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6044)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6044)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=5972)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=5972)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6044)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6044)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6112)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6112)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6042)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6042)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6112)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6112)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6182)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6182)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6114)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6114)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6182)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6182)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6252)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6252)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6184)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6184)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6252)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6252)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:43:59,835 | server.py:187 | evaluate_round 8 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:43:59,837 | server.py:222 | fit_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6254)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6254)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m [Client 0, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.4598 | Train_acc: 82.0602 % | Validation_loss: 0.9706 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6333)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6333)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6333)\u001b[0m [Client 3, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6333)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0236 | Train_acc: 99.6528 % | Validation_loss: 1.0838 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0127 | Train_acc: 99.3056 % | Validation_loss: 1.0640 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6332)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0112 | Train_acc: 99.3056 % | Validation_loss: 1.0717 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6333)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6333)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0029 | Train_acc: 100.0000 % | Validation_loss: 1.2349 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m [Client 9, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2088 | Train_acc: 90.9722 % | Validation_loss: 0.9025 | Validation_acc: 72.4138 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.79s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m [Client 7, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0286 | Train_acc: 99.3056 % | Validation_loss: 0.9183 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0050 | Train_acc: 100.0000 % | Validation_loss: 1.1670 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6407)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0028 | Train_acc: 100.0000 % | Validation_loss: 1.1215 | Validation_acc: 65.5172 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6405)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m [Client 5, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.80s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.3214 | Train_acc: 85.8796 % | Validation_loss: 1.0825 | Validation_acc: 50.0000 %\n",
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m [Client 1, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.84s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0184 | Train_acc: 100.0000 % | Validation_loss: 2.0610 | Validation_acc: 46.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0066 | Train_acc: 100.0000 % | Validation_loss: 1.2014 | Validation_acc: 67.8571 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6479)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0035 | Train_acc: 100.0000 % | Validation_loss: 1.2516 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6481)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m [Client 8, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2554 | Train_acc: 89.5833 % | Validation_loss: 1.2897 | Validation_acc: 75.0000 %\n",
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m [Client 4, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.84s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0146 | Train_acc: 100.0000 % | Validation_loss: 0.7988 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0158 | Train_acc: 100.0000 % | Validation_loss: 1.1924 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6553)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0137 | Train_acc: 99.6528 % | Validation_loss: 1.2051 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6555)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0028 | Train_acc: 100.0000 % | Validation_loss: 0.7284 | Validation_acc: 78.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m [Client 2, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.3029 | Train_acc: 88.8889 % | Validation_loss: 0.5788 | Validation_acc: 78.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6629)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=6629)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6629)\u001b[0m [Client 6, round 9] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 9, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=6629)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.82s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0133 | Train_acc: 99.6528 % | Validation_loss: 0.6998 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0044 | Train_acc: 100.0000 % | Validation_loss: 0.7233 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=6627)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=6629)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0032 | Train_acc: 100.0000 % | Validation_loss: 1.0519 | Validation_acc: 67.8571 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.80s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-07-24 04:46:28,530 | server.py:236 | fit_round 9 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 9 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:46:30,555 | server.py:125 | fit progress: (9, 0.756576085801829, {'accuracy': 64.48863636363636}, 1819.0904443759998)\n",
      "DEBUG flwr 2024-07-24 04:46:30,556 | server.py:173 | evaluate_round 9: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.756576085801829 / accuracy 64.48863636363636\n",
      "\u001b[36m(launch_and_evaluate pid=6710)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=6710)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=6629)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=6710)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6710)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6780)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6780)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6711)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6711)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6780)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6780)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6850)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6850)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6782)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6782)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6850)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6850)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6920)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6920)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6852)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6852)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6920)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6920)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6991)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6991)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6922)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6922)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=6991)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6991)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:47:31,646 | server.py:187 | evaluate_round 9 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:47:31,648 | server.py:222 | fit_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7070)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7070)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=6993)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=6993)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m [Client 1, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2441 | Train_acc: 92.3611 % | Validation_loss: 0.9269 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7070)\u001b[0m [Client 3, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7070)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0084 | Train_acc: 100.0000 % | Validation_loss: 1.2542 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0028 | Train_acc: 100.0000 % | Validation_loss: 1.3653 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7071)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0018 | Train_acc: 100.0000 % | Validation_loss: 1.3816 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7070)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7070)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0094 | Train_acc: 99.6528 % | Validation_loss: 1.6158 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m [Client 9, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2132 | Train_acc: 92.0455 % | Validation_loss: 0.9298 | Validation_acc: 65.5172 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m [Client 2, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0326 | Train_acc: 98.9583 % | Validation_loss: 0.9817 | Validation_acc: 65.5172 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:11,  1.84s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0041 | Train_acc: 100.0000 % | Validation_loss: 0.7544 | Validation_acc: 82.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7146)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0024 | Train_acc: 100.0000 % | Validation_loss: 0.7646 | Validation_acc: 82.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7144)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0054 | Train_acc: 100.0000 % | Validation_loss: 0.8318 | Validation_acc: 55.1724 %\n",
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m [Client 0, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2303 | Train_acc: 91.3194 % | Validation_loss: 0.9601 | Validation_acc: 42.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:22,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7220)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7220)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7220)\u001b[0m [Client 6, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7220)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0294 | Train_acc: 99.6528 % | Validation_loss: 1.1520 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:11,  1.83s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0209 | Train_acc: 99.6528 % | Validation_loss: 1.1300 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7218)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0165 | Train_acc: 99.6528 % | Validation_loss: 1.0520 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7220)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7220)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0047 | Train_acc: 100.0000 % | Validation_loss: 1.0643 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m [Client 4, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:22,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2307 | Train_acc: 90.6250 % | Validation_loss: 0.8994 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m [Client 7, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.81s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0086 | Train_acc: 100.0000 % | Validation_loss: 1.4380 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0038 | Train_acc: 100.0000 % | Validation_loss: 1.2998 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7294)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0014 | Train_acc: 100.0000 % | Validation_loss: 1.5188 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7292)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0016 | Train_acc: 100.0000 % | Validation_loss: 0.9988 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m [Client 8, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.83s/it]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2231 | Train_acc: 91.6667 % | Validation_loss: 1.0171 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m [Client 5, round 10] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 10, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.81s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0072 | Train_acc: 99.6528 % | Validation_loss: 1.6412 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0028 | Train_acc: 100.0000 % | Validation_loss: 1.8889 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7368)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.82s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0062 | Train_acc: 99.6528 % | Validation_loss: 1.3952 | Validation_acc: 60.7143 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:50:01,099 | server.py:236 | fit_round 10 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 10 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:50:03,148 | server.py:125 | fit progress: (10, 0.7342284294691953, {'accuracy': 63.35227272727273}, 2031.683543256)\n",
      "DEBUG flwr 2024-07-24 04:50:03,149 | server.py:173 | evaluate_round 10: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.7342284294691953 / accuracy 63.35227272727273\n",
      "\u001b[36m(launch_and_evaluate pid=7450)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=7450)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7366)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=7450)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7450)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7521)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7521)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7449)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7449)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7521)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7519)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7589)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7589)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7519)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7521)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7589)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7591)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7659)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7659)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7591)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7589)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7659)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7659)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7732)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7732)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7661)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7661)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=7732)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7732)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:51:03,413 | server.py:187 | evaluate_round 10 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:51:03,414 | server.py:222 | fit_round 11: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=7731)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=7731)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m [Client 2, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2896 | Train_acc: 86.2269 % | Validation_loss: 0.7761 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7810)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7810)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7810)\u001b[0m [Client 1, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7810)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.83s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7810)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0124 | Train_acc: 100.0000 % | Validation_loss: 1.2472 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0019 | Train_acc: 100.0000 % | Validation_loss: 0.8607 | Validation_acc: 75.0000 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.74s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7810)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0014 | Train_acc: 100.0000 % | Validation_loss: 0.8916 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7809)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m [Client 7, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1551 | Train_acc: 95.1389 % | Validation_loss: 1.0889 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7884)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7884)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7884)\u001b[0m [Client 9, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7884)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0108 | Train_acc: 99.6528 % | Validation_loss: 1.4603 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0013 | Train_acc: 100.0000 % | Validation_loss: 1.4506 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7882)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0011 | Train_acc: 100.0000 % | Validation_loss: 1.4323 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7884)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7884)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0017 | Train_acc: 100.0000 % | Validation_loss: 1.0008 | Validation_acc: 72.4138 %\n",
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m [Client 0, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2135 | Train_acc: 90.9722 % | Validation_loss: 0.9554 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7958)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=7958)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7958)\u001b[0m [Client 5, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=7958)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0147 | Train_acc: 99.6528 % | Validation_loss: 1.2095 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0083 | Train_acc: 99.3056 % | Validation_loss: 1.2505 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7956)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0084 | Train_acc: 99.3056 % | Validation_loss: 1.2155 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=7958)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=7958)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0014 | Train_acc: 100.0000 % | Validation_loss: 1.9638 | Validation_acc: 53.5714 %\n",
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m [Client 6, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2056 | Train_acc: 89.0046 % | Validation_loss: 1.0647 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8032)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8032)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8032)\u001b[0m [Client 4, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8032)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0032 | Train_acc: 100.0000 % | Validation_loss: 1.2522 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0014 | Train_acc: 100.0000 % | Validation_loss: 1.3532 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8030)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0012 | Train_acc: 100.0000 % | Validation_loss: 1.3902 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8032)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8032)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0018 | Train_acc: 100.0000 % | Validation_loss: 0.9379 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m [Client 3, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2101 | Train_acc: 91.3194 % | Validation_loss: 0.9992 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8106)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8106)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8106)\u001b[0m [Client 8, round 11] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 11, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8106)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0065 | Train_acc: 100.0000 % | Validation_loss: 1.0666 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.0016 | Train_acc: 100.0000 % | Validation_loss: 1.1720 | Validation_acc: 71.4286 %\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:13<00:03,  1.69s/it]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8104)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:53:28,986 | server.py:236 | fit_round 11 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 11 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:53:31,010 | server.py:125 | fit progress: (11, 0.7459455730224197, {'accuracy': 63.92045454545454}, 2239.545071815)\n",
      "DEBUG flwr 2024-07-24 04:53:31,011 | server.py:173 | evaluate_round 11: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.7459455730224197 / accuracy 63.92045454545454\n",
      "\u001b[36m(launch_and_evaluate pid=8187)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=8187)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8106)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0021 | Train_acc: 100.0000 % | Validation_loss: 1.3716 | Validation_acc: 57.1429 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8106)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=8187)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8187)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8258)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8258)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8188)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8188)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8258)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8260)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8328)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8328)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8260)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8258)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8328)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8328)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8398)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8398)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8330)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8330)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8398)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8398)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8469)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8469)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8400)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8400)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8471)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8471)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:54:31,146 | server.py:187 | evaluate_round 11 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:54:31,147 | server.py:222 | fit_round 12: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8469)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8469)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m [Client 8, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1381 | Train_acc: 94.7917 % | Validation_loss: 1.1071 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.78s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8548)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8548)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8548)\u001b[0m [Client 1, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8548)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0060 | Train_acc: 99.6528 % | Validation_loss: 1.5186 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0092 | Train_acc: 99.6528 % | Validation_loss: 1.5780 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8549)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8624)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8624)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8548)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0011 | Train_acc: 100.0000 % | Validation_loss: 1.4043 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8548)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8624)\u001b[0m [Client 9, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8624)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0064 | Train_acc: 100.0000 % | Validation_loss: 1.1885 | Validation_acc: 71.4286 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m [Client 7, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0018 | Train_acc: 100.0000 % | Validation_loss: 1.3875 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0010 | Train_acc: 100.0000 % | Validation_loss: 1.4534 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8622)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8624)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0014 | Train_acc: 100.0000 % | Validation_loss: 0.9619 | Validation_acc: 65.5172 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8624)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m [Client 6, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.80s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8698)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8698)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0169 | Train_acc: 99.6528 % | Validation_loss: 1.2139 | Validation_acc: 67.8571 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8698)\u001b[0m [Client 4, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8698)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0035 | Train_acc: 100.0000 % | Validation_loss: 1.2242 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0040 | Train_acc: 100.0000 % | Validation_loss: 1.0597 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8696)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8698)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0741 | Train_acc: 97.2222 % | Validation_loss: 1.0377 | Validation_acc: 78.5714 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8698)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m [Client 0, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8772)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8772)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0633 | Train_acc: 98.9583 % | Validation_loss: 1.0178 | Validation_acc: 60.7143 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8772)\u001b[0m [Client 3, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8772)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0245 | Train_acc: 99.6528 % | Validation_loss: 1.0941 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0167 | Train_acc: 99.6528 % | Validation_loss: 1.0088 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8772)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0084 | Train_acc: 99.6528 % | Validation_loss: 0.9381 | Validation_acc: 64.2857 %\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8770)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m [Client 2, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0330 | Train_acc: 98.9583 % | Validation_loss: 0.9238 | Validation_acc: 75.0000 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m [Client 5, round 12] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 12, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.76s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.66s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0015 | Train_acc: 100.0000 % | Validation_loss: 2.0188 | Validation_acc: 53.5714 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8845)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0016 | Train_acc: 100.0000 % | Validation_loss: 0.7883 | Validation_acc: 71.4286 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:16<00:00,  1.70s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-07-24 04:56:57,562 | server.py:236 | fit_round 12 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 12 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 04:56:59,571 | server.py:125 | fit progress: (12, 0.7624565901404078, {'accuracy': 63.63636363636363}, 2448.106195373)\n",
      "DEBUG flwr 2024-07-24 04:56:59,572 | server.py:173 | evaluate_round 12: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.7624565901404078 / accuracy 63.63636363636363\n",
      "\u001b[36m(launch_and_evaluate pid=8927)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=8927)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=8846)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0010 | Train_acc: 100.0000 % | Validation_loss: 2.3007 | Validation_acc: 53.5714 %\n",
      "\u001b[36m(launch_and_evaluate pid=8927)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8927)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8998)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8998)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=8928)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8928)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=8998)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=8998)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9068)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9068)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9000)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9000)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9068)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9068)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9138)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9138)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9070)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9070)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9138)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9138)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9208)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9208)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9140)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9140)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9208)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9208)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 04:58:00,152 | server.py:187 | evaluate_round 12 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 04:58:00,153 | server.py:222 | fit_round 13: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9218)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9218)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m [Client 7, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:16<00:00,  1.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2358 | Train_acc: 87.7315 % | Validation_loss: 1.3717 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m [Client 1, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0081 | Train_acc: 100.0000 % | Validation_loss: 1.6646 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0012 | Train_acc: 100.0000 % | Validation_loss: 1.5586 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.69s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9287)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0007 | Train_acc: 100.0000 % | Validation_loss: 1.6308 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9288)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0010 | Train_acc: 100.0000 % | Validation_loss: 1.4851 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m [Client 0, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1848 | Train_acc: 93.4028 % | Validation_loss: 1.1188 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:22,  2.46s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9362)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9362)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9362)\u001b[0m [Client 9, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9362)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0118 | Train_acc: 99.6528 % | Validation_loss: 1.2486 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0063 | Train_acc: 99.6528 % | Validation_loss: 1.2849 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9360)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0084 | Train_acc: 99.6528 % | Validation_loss: 1.2090 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9362)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9362)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0011 | Train_acc: 100.0000 % | Validation_loss: 0.9492 | Validation_acc: 75.8621 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m [Client 6, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2215 | Train_acc: 93.0556 % | Validation_loss: 0.8548 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=9459)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9459)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9459)\u001b[0m [Client 3, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9459)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.82s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0159 | Train_acc: 99.6528 % | Validation_loss: 1.2204 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0019 | Train_acc: 100.0000 % | Validation_loss: 1.2289 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9434)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0010 | Train_acc: 100.0000 % | Validation_loss: 1.3309 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9459)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9459)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0019 | Train_acc: 100.0000 % | Validation_loss: 1.4319 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m [Client 8, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1298 | Train_acc: 93.4028 % | Validation_loss: 1.1319 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9533)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9533)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9533)\u001b[0m [Client 2, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9533)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0319 | Train_acc: 99.3056 % | Validation_loss: 1.2860 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:11,  1.84s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0013 | Train_acc: 100.0000 % | Validation_loss: 1.4176 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9508)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 1.4530 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9533)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9533)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0010 | Train_acc: 100.0000 % | Validation_loss: 0.9863 | Validation_acc: 75.0000 %\n",
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m [Client 5, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1317 | Train_acc: 94.4444 % | Validation_loss: 1.7118 | Validation_acc: 46.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9607)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=9607)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9607)\u001b[0m [Client 4, round 13] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 13, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=9607)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0073 | Train_acc: 99.6528 % | Validation_loss: 2.7493 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0020 | Train_acc: 100.0000 % | Validation_loss: 2.3282 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=9582)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=9607)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0012 | Train_acc: 100.0000 % | Validation_loss: 1.1237 | Validation_acc: 71.4286 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "DEBUG flwr 2024-07-24 05:00:28,233 | server.py:236 | fit_round 13 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 13 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:00:30,248 | server.py:125 | fit progress: (13, 0.8462171556258743, {'accuracy': 63.92045454545454}, 2658.7834913300003)\n",
      "DEBUG flwr 2024-07-24 05:00:30,249 | server.py:173 | evaluate_round 13: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.8462171556258743 / accuracy 63.92045454545454\n",
      "\u001b[36m(launch_and_evaluate pid=9665)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=9665)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=9607)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=9665)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9665)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9738)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9738)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9666)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9666)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9738)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9738)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9806)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9806)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9736)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9736)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9806)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9806)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9876)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9876)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9808)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9808)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9876)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9876)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9948)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9948)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9878)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9878)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=9948)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9948)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:01:30,959 | server.py:187 | evaluate_round 13 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:01:30,961 | server.py:222 | fit_round 14: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=9946)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=9946)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m [Client 4, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1464 | Train_acc: 92.3611 % | Validation_loss: 0.9962 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m [Client 7, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0092 | Train_acc: 99.6528 % | Validation_loss: 1.6273 | Validation_acc: 71.4286 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0017 | Train_acc: 100.0000 % | Validation_loss: 1.2101 | Validation_acc: 71.4286 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.77s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10027)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0009 | Train_acc: 100.0000 % | Validation_loss: 1.2236 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10026)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.5009 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m [Client 0, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\n",
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1306 | Train_acc: 94.7917 % | Validation_loss: 1.1639 | Validation_acc: 53.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10101)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10101)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10101)\u001b[0m [Client 9, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10101)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0223 | Train_acc: 99.3056 % | Validation_loss: 1.3873 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0071 | Train_acc: 99.6528 % | Validation_loss: 1.2725 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10099)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0065 | Train_acc: 99.6528 % | Validation_loss: 1.3812 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10101)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10101)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.1158 | Validation_acc: 72.4138 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m [Client 5, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1508 | Train_acc: 95.4861 % | Validation_loss: 1.6380 | Validation_acc: 53.5714 %\n",
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m  To get the checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m [Client 3, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0259 | Train_acc: 99.6528 % | Validation_loss: 2.7347 | Validation_acc: 50.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.74s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0022 | Train_acc: 100.0000 % | Validation_loss: 1.3945 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10173)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.4434 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10198)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m [Client 1, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1570 | Train_acc: 94.0972 % | Validation_loss: 1.2810 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=10272)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10272)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10272)\u001b[0m [Client 6, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10272)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0012 | Train_acc: 100.0000 % | Validation_loss: 1.7238 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.6938 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10247)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.7020 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10272)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10272)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0010 | Train_acc: 100.0000 % | Validation_loss: 1.3354 | Validation_acc: 60.7143 %\n",
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m [Client 2, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1328 | Train_acc: 94.4444 % | Validation_loss: 1.1356 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.17s/it]\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m [Client 8, round 14] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 14, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0110 | Train_acc: 99.3056 % | Validation_loss: 0.7488 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.69s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0015 | Train_acc: 100.0000 % | Validation_loss: 1.5108 | Validation_acc: 67.8571 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10321)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:03:58,906 | server.py:236 | fit_round 14 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 14 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:04:00,964 | server.py:125 | fit progress: (14, 0.8497073252431371, {'accuracy': 62.5}, 2869.4991606030003)\n",
      "DEBUG flwr 2024-07-24 05:04:00,965 | server.py:173 | evaluate_round 14: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.8497073252431371 / accuracy 62.5\n",
      "\u001b[36m(launch_and_evaluate pid=10405)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=10405)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0007 | Train_acc: 100.0000 % | Validation_loss: 1.5352 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10346)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=10405)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10405)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10475)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10475)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10404)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10404)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10475)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10475)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10545)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10545)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10477)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10477)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10545)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10545)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10616)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10616)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10547)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10547)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10616)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10616)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10686)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10686)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10618)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10618)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=10686)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10686)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:05:01,486 | server.py:187 | evaluate_round 14 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:05:01,487 | server.py:222 | fit_round 15: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=10688)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=10688)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m [Client 8, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1327 | Train_acc: 95.1389 % | Validation_loss: 1.2821 | Validation_acc: 60.7143 %\n",
      "\u001b[36m(launch_and_fit pid=10767)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10767)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10767)\u001b[0m [Client 3, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10767)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0022 | Train_acc: 100.0000 % | Validation_loss: 1.6466 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.2148 | Train_acc: 94.4444 % | Validation_loss: 1.1408 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10766)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0058 | Train_acc: 99.6528 % | Validation_loss: 1.2740 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10767)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10767)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.8904 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.75s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m [Client 6, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1270 | Train_acc: 94.7917 % | Validation_loss: 1.1368 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10842)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10842)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10842)\u001b[0m [Client 5, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10842)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0017 | Train_acc: 100.0000 % | Validation_loss: 1.2826 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.2584 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10840)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.2815 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10842)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10842)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 2.2556 | Validation_acc: 53.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m [Client 2, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1684 | Train_acc: 93.0556 % | Validation_loss: 1.0353 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.79s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m [Client 4, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0054 | Train_acc: 99.6528 % | Validation_loss: 1.0489 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0009 | Train_acc: 100.0000 % | Validation_loss: 1.4827 | Validation_acc: 64.2857 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10914)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.4634 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=10916)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m [Client 1, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1032 | Train_acc: 96.5278 % | Validation_loss: 1.4975 | Validation_acc: 57.1429 %\n",
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m [Client 0, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0017 | Train_acc: 100.0000 % | Validation_loss: 1.5914 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0213 | Train_acc: 99.6528 % | Validation_loss: 1.4647 | Validation_acc: 57.1429 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.69s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=10989)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0097 | Train_acc: 99.6528 % | Validation_loss: 1.4450 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11013)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.73s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m [Client 9, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 0.0323 | Train_acc: 99.3056 % | Validation_loss: 1.2483 | Validation_acc: 75.0000 %\u001b[32m [repeated 4x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.88s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m [Client 7, round 15] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 15, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.1301 | Validation_acc: 68.9655 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.1758 | Validation_acc: 65.5172 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11063)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:07:29,088 | server.py:236 | fit_round 15 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 15 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:07:31,085 | server.py:125 | fit progress: (15, 0.8507100167599592, {'accuracy': 61.36363636363637}, 3079.620001155)\n",
      "DEBUG flwr 2024-07-24 05:07:31,086 | server.py:173 | evaluate_round 15: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.8507100167599592 / accuracy 61.36363636363637\n",
      "\u001b[36m(launch_and_evaluate pid=11146)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=11146)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.4921 | Validation_acc: 67.8571 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11065)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=11146)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11146)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11216)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11216)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11147)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11147)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11216)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11216)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11286)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11286)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11218)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11218)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11286)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11286)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11359)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11359)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11288)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11288)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11359)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11359)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11427)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11427)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11357)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11357)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11427)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11427)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:08:31,134 | server.py:187 | evaluate_round 15 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:08:31,136 | server.py:222 | fit_round 16: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11429)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11429)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.72s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m [Client 7, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1162 | Train_acc: 95.8333 % | Validation_loss: 1.0559 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.88s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11507)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11507)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11507)\u001b[0m [Client 5, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11507)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0013 | Train_acc: 100.0000 % | Validation_loss: 1.4298 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.8840 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11506)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.9753 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11582)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11582)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11507)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11507)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 2.6144 | Validation_acc: 50.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m [Client 3, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1112 | Train_acc: 96.1806 % | Validation_loss: 0.6827 | Validation_acc: 78.5714 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11582)\u001b[0m [Client 9, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11582)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:11,  1.87s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0170 | Train_acc: 100.0000 % | Validation_loss: 1.2268 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.5917 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11580)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.4968 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11582)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11582)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.1125 | Validation_acc: 65.5172 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m [Client 6, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1089 | Train_acc: 95.1389 % | Validation_loss: 1.0691 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11656)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11656)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11656)\u001b[0m [Client 8, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11656)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:11,  1.89s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 1.3277 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.4474 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11654)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.4833 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11656)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11656)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0007 | Train_acc: 100.0000 % | Validation_loss: 1.5061 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m [Client 2, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1935 | Train_acc: 87.9630 % | Validation_loss: 1.3296 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:20,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11730)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11730)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11730)\u001b[0m [Client 1, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11730)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0017 | Train_acc: 100.0000 % | Validation_loss: 0.9341 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 0.9993 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11728)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.0504 | Validation_acc: 78.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11730)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11730)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0011 | Train_acc: 100.0000 % | Validation_loss: 1.9298 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m [Client 4, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1755 | Train_acc: 94.4444 % | Validation_loss: 0.9639 | Validation_acc: 64.2857 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m [Client 0, round 16] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 16, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0041 | Train_acc: 100.0000 % | Validation_loss: 1.2260 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|\u001b[34m███████   \u001b[0m| 7/10 [00:12<00:05,  1.79s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0762 | Train_acc: 95.6019 % | Validation_loss: 1.3499 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11802)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.5555 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:10:58,373 | server.py:236 | fit_round 16 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 16 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:11:00,397 | server.py:125 | fit progress: (16, 0.9239390754902904, {'accuracy': 63.63636363636363}, 3288.9322962300002)\n",
      "DEBUG flwr 2024-07-24 05:11:00,398 | server.py:173 | evaluate_round 16: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9239390754902904 / accuracy 63.63636363636363\n",
      "\u001b[36m(launch_and_evaluate pid=11885)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=11885)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=11804)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0289 | Train_acc: 99.3056 % | Validation_loss: 1.1127 | Validation_acc: 57.1429 %\n",
      "\u001b[36m(launch_and_evaluate pid=11885)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11885)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11955)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11955)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11886)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11886)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=11955)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11955)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12025)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12025)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=11957)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=11957)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12025)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12025)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12096)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12096)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12027)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12027)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12096)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12096)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12166)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12166)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12098)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12098)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12166)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12166)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:12:00,731 | server.py:187 | evaluate_round 16 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:12:00,732 | server.py:222 | fit_round 17: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12191)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12191)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m [Client 5, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|\u001b[34m█         \u001b[0m| 1/10 [00:02<00:19,  2.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1408 | Train_acc: 95.8333 % | Validation_loss: 1.9579 | Validation_acc: 57.1429 %\n",
      "\u001b[36m(launch_and_fit pid=12247)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12247)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12247)\u001b[0m [Client 8, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12247)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 40%|\u001b[34m████      \u001b[0m| 4/10 [00:07<00:10,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 2.9205 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 8/10 [00:14<00:03,  1.78s/it]\u001b[32m [repeated 8x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m \tTrain Epoch: 8 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 2.7446 | Validation_acc: 53.5714 %\u001b[32m [repeated 8x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12246)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12247)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0199 | Train_acc: 100.0000 % | Validation_loss: 1.3355 | Validation_acc: 71.4286 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12247)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m [Client 1, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0027 | Train_acc: 100.0000 % | Validation_loss: 1.6071 | Validation_acc: 71.4286 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m [Client 3, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.5391 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.7005 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.80s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12320)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.7608 | Validation_acc: 67.8571 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12322)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m [Client 2, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.85s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0197 | Train_acc: 98.9583 % | Validation_loss: 1.1076 | Validation_acc: 75.0000 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m [Client 4, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0013 | Train_acc: 100.0000 % | Validation_loss: 1.0340 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.4265 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12396)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.4245 | Validation_acc: 60.7143 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12394)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m [Client 9, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0033 | Train_acc: 100.0000 % | Validation_loss: 0.9810 | Validation_acc: 65.5172 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m [Client 0, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.83s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0105 | Train_acc: 100.0000 % | Validation_loss: 0.9138 | Validation_acc: 65.5172 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0057 | Train_acc: 99.3056 % | Validation_loss: 1.6182 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12468)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0058 | Train_acc: 99.6528 % | Validation_loss: 1.6758 | Validation_acc: 60.7143 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12470)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m [Client 6, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12542)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12542)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 0.0040 | Train_acc: 100.0000 % | Validation_loss: 1.3190 | Validation_acc: 71.4286 %\u001b[32m [repeated 5x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12542)\u001b[0m [Client 7, round 17] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 17, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12542)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m \tTrain Epoch: 6 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.3351 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m \tTrain Epoch: 9 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.4412 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12544)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:14:28,336 | server.py:236 | fit_round 17 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 17 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:14:30,366 | server.py:125 | fit progress: (17, 0.9248961626806043, {'accuracy': 63.92045454545454}, 3498.9015874240004)\n",
      "DEBUG flwr 2024-07-24 05:14:30,368 | server.py:173 | evaluate_round 17: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9248961626806043 / accuracy 63.92045454545454\n",
      "\u001b[36m(launch_and_evaluate pid=12625)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=12625)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12542)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.4931 | Validation_acc: 67.8571 %\u001b[32m [repeated 3x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12542)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=12625)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12625)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12698)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12698)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12626)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12626)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12698)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12698)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12766)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12766)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12696)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12696)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12766)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12766)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12838)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12838)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12768)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12768)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12838)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12838)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12908)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12908)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12836)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12836)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=12908)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12908)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:15:31,023 | server.py:187 | evaluate_round 17 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:15:31,024 | server.py:222 | fit_round 18: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=12906)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=12906)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m [Client 0, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12987)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0913 | Train_acc: 97.5694 % | Validation_loss: 1.4960 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=12987)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=12987)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12987)\u001b[0m [Client 9, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.81s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0096 | Train_acc: 99.6528 % | Validation_loss: 1.5610 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0065 | Train_acc: 99.6528 % | Validation_loss: 1.5911 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12986)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0053 | Train_acc: 99.6528 % | Validation_loss: 1.5394 | Validation_acc: 53.5714 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=12987)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=12987)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.0653 | Validation_acc: 75.8621 %\n",
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m [Client 7, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1342 | Train_acc: 95.8333 % | Validation_loss: 0.9396 | Validation_acc: 78.5714 %\n",
      "\u001b[36m(launch_and_fit pid=13062)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13062)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13062)\u001b[0m [Client 8, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13062)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0013 | Train_acc: 100.0000 % | Validation_loss: 1.2830 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.4926 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13060)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.5525 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13062)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13062)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.5574 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m [Client 6, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.2119 | Train_acc: 88.0787 % | Validation_loss: 1.1539 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=13136)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13136)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13136)\u001b[0m [Client 3, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13136)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0030 | Train_acc: 100.0000 % | Validation_loss: 1.3792 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.4834 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13135)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.4788 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13136)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13136)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.9341 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m [Client 2, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1062 | Train_acc: 95.8333 % | Validation_loss: 1.2367 | Validation_acc: 75.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.83s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13208)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13208)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13208)\u001b[0m [Client 5, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13208)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0376 | Train_acc: 98.6111 % | Validation_loss: 0.7239 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0038 | Train_acc: 100.0000 % | Validation_loss: 0.7481 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13210)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 0.9321 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13282)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13282)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13208)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13208)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 2.9743 | Validation_acc: 50.0000 %\n",
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m [Client 4, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.76s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1061 | Train_acc: 95.8333 % | Validation_loss: 1.2072 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13282)\u001b[0m [Client 1, round 18] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 18, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13282)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.83s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0011 | Train_acc: 100.0000 % | Validation_loss: 1.8227 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.6161 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.70s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13284)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13282)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.7824 | Validation_acc: 67.8571 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:17:59,019 | server.py:236 | fit_round 18 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 18 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:18:01,046 | server.py:125 | fit progress: (18, 0.9564968906342983, {'accuracy': 62.5}, 3709.581663288)\n",
      "DEBUG flwr 2024-07-24 05:18:01,047 | server.py:173 | evaluate_round 18: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9564968906342983 / accuracy 62.5\n",
      "\u001b[36m(launch_and_evaluate pid=13365)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=13365)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13282)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_evaluate pid=13365)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13365)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13435)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13435)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13366)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13366)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13435)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13435)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13506)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13506)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13437)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13437)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13506)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13506)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13576)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13576)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13508)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13508)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13576)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13576)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13646)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13646)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13578)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13578)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=13646)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13646)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:19:02,113 | server.py:187 | evaluate_round 18 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:19:02,114 | server.py:222 | fit_round 19: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=13671)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=13671)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m [Client 6, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0756 | Train_acc: 96.8750 % | Validation_loss: 1.2434 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m [Client 1, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.94s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 1.6093 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.8307 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13726)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.8544 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13725)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.6011 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.82s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m [Client 9, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0634 | Train_acc: 96.8750 % | Validation_loss: 1.4412 | Validation_acc: 68.9655 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.87s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m [Client 0, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0141 | Train_acc: 99.6528 % | Validation_loss: 1.4445 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.78s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0056 | Train_acc: 99.3056 % | Validation_loss: 1.5184 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13800)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0053 | Train_acc: 99.3056 % | Validation_loss: 1.5065 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13798)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.4226 | Validation_acc: 75.8621 %\n",
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m [Client 2, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.83s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.1100 | Train_acc: 95.4861 % | Validation_loss: 1.0698 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=13874)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13874)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13874)\u001b[0m [Client 3, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13874)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0017 | Train_acc: 100.0000 % | Validation_loss: 0.9536 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.2979 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.76s/it]\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13872)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.2428 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13874)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13874)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.7901 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:18<00:00,  1.81s/it]\u001b[32m [repeated 2x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m [Client 8, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0902 | Train_acc: 96.5278 % | Validation_loss: 1.5455 | Validation_acc: 57.1429 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13971)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=13971)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13971)\u001b[0m [Client 5, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=13971)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0014 | Train_acc: 100.0000 % | Validation_loss: 1.6238 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:11<00:07,  1.85s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0006 | Train_acc: 100.0000 % | Validation_loss: 1.6777 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.77s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13946)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.6766 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=13971)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=13971)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 3.2516 | Validation_acc: 50.0000 %\n",
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m [Client 7, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0765 | Train_acc: 98.2639 % | Validation_loss: 1.1410 | Validation_acc: 75.0000 %\n",
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m [Client 4, round 19] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 19, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:13,  1.86s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0174 | Train_acc: 100.0000 % | Validation_loss: 1.7893 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:07,  1.76s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.5796 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:16<00:01,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14020)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0004 | Train_acc: 100.0000 % | Validation_loss: 1.7686 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:21:30,742 | server.py:236 | fit_round 19 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 19 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:21:32,815 | server.py:125 | fit progress: (19, 0.9629694619639353, {'accuracy': 64.77272727272727}, 3921.349998512)\n",
      "DEBUG flwr 2024-07-24 05:21:32,816 | server.py:173 | evaluate_round 19: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9629694619639353 / accuracy 64.77272727272727\n",
      "\u001b[36m(launch_and_evaluate pid=14103)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=14103)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14022)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.5280 | Validation_acc: 60.7143 %\n",
      "\u001b[36m(launch_and_evaluate pid=14103)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14103)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14174)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14174)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14104)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14104)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14174)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14174)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14244)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14244)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14176)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14176)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14244)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14244)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14314)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14314)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14246)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14246)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14314)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14314)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14384)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14384)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14316)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14316)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14384)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14384)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:22:33,792 | server.py:187 | evaluate_round 19 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-24 05:22:33,793 | server.py:222 | fit_round 20: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14386)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14386)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m [Client 4, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.79s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0779 | Train_acc: 96.8750 % | Validation_loss: 1.4509 | Validation_acc: 71.4286 %\n",
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m [Client 6, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0018 | Train_acc: 100.0000 % | Validation_loss: 1.3657 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.7573 | Validation_acc: 60.7143 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.74s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14464)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.4723 | Validation_acc: 64.2857 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14463)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.7667 | Validation_acc: 60.7143 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.77s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m [Client 8, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0907 | Train_acc: 97.5694 % | Validation_loss: 1.1293 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.79s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14539)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14539)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14539)\u001b[0m [Client 0, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14539)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0020 | Train_acc: 100.0000 % | Validation_loss: 1.4392 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.5225 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.75s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14537)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.5432 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14539)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14539)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0056 | Train_acc: 99.6528 % | Validation_loss: 1.4684 | Validation_acc: 64.2857 %\n",
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m [Client 5, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0839 | Train_acc: 96.8750 % | Validation_loss: 2.5216 | Validation_acc: 53.5714 %\n",
      "\u001b[36m(launch_and_fit pid=14613)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14613)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14613)\u001b[0m [Client 3, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14613)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.82s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0021 | Train_acc: 100.0000 % | Validation_loss: 2.8073 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.72s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0029 | Train_acc: 100.0000 % | Validation_loss: 2.2123 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14611)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0031 | Train_acc: 100.0000 % | Validation_loss: 2.5434 | Validation_acc: 57.1429 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=14685)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14685)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14613)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14613)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.8594 | Validation_acc: 67.8571 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.78s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14685)\u001b[0m [Client 2, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14685)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=14685)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0615 | Train_acc: 97.9167 % | Validation_loss: 1.4299 | Validation_acc: 71.4286 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.79s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m [Client 1, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0005 | Train_acc: 100.0000 % | Validation_loss: 1.6555 | Validation_acc: 75.0000 %\u001b[32m [repeated 7x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.70s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.8279 | Validation_acc: 75.0000 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.68s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14685)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.8542 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14687)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m [Client 7, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      "100%|\u001b[34m██████████\u001b[0m| 10/10 [00:17<00:00,  1.74s/it]\u001b[32m [repeated 3x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 0.0615 | Train_acc: 97.5694 % | Validation_loss: 1.3064 | Validation_acc: 67.8571 %\n",
      "\u001b[36m(launch_and_fit pid=14784)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=14784)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14784)\u001b[0m [Client 9, round 20] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 20, 'local_epochs': 10}\n",
      "\u001b[36m(launch_and_fit pid=14784)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/10 [00:00<?, ?it/s]\n",
      " 30%|\u001b[34m███       \u001b[0m| 3/10 [00:05<00:12,  1.80s/it]\u001b[32m [repeated 5x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 0.0183 | Train_acc: 99.6528 % | Validation_loss: 1.0178 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 6/10 [00:10<00:06,  1.73s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m \tTrain Epoch: 7 \tTrain_loss: 0.0008 | Train_acc: 100.0000 % | Validation_loss: 1.8232 | Validation_acc: 71.4286 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|\u001b[34m█████████ \u001b[0m| 9/10 [00:15<00:01,  1.71s/it]\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14759)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0003 | Train_acc: 100.0000 % | Validation_loss: 1.5528 | Validation_acc: 67.8571 %\u001b[32m [repeated 6x across cluster]\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:25:01,185 | server.py:236 | fit_round 20 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 20 aggregated_parameters...\n",
      "Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-24 05:25:03,269 | server.py:125 | fit progress: (20, 0.9463489573787559, {'accuracy': 63.06818181818182}, 4131.803835042)\n",
      "DEBUG flwr 2024-07-24 05:25:03,270 | server.py:173 | evaluate_round 20: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server-side evaluation loss 0.9463489573787559 / accuracy 63.06818181818182\n",
      "\u001b[36m(launch_and_evaluate pid=14842)\u001b[0m Run WITHOUT homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=14842)\u001b[0m  To get the checkpoint\n",
      "\u001b[36m(launch_and_fit pid=14784)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=14784)\u001b[0m \tTrain Epoch: 10 \tTrain_loss: 0.0002 | Train_acc: 100.0000 % | Validation_loss: 1.0970 | Validation_acc: 79.3103 %\n",
      "\u001b[36m(launch_and_evaluate pid=14842)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14842)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14913)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14913)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14843)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14843)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14913)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14913)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14983)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14983)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14915)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14915)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=14983)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14983)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=15053)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=15053)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=14985)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=14985)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=15053)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=15053)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=15123)\u001b[0m Run WITHOUT homomorphic encryption\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=15123)\u001b[0m  To get the checkpoint\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(launch_and_evaluate pid=15078)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=15078)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=15123)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=15123)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-24 05:26:03,991 | server.py:187 | evaluate_round 20 received 10 results and 0 failures\n",
      "INFO flwr 2024-07-24 05:26:03,992 | server.py:153 | FL finished in 4192.527627539\n",
      "INFO flwr 2024-07-24 05:26:04,030 | app.py:225 | app_fit: losses_distributed [(1, 0.637817668914795), (2, 0.6280321300029754), (3, 0.6352152824401855), (4, 0.6314563572406768), (5, 0.6044644951820374), (6, 0.6773597478866578), (7, 0.7431467473506927), (8, 0.8107650578022003), (9, 0.7681194722652436), (10, 0.8061315953731537), (11, 0.8402504563331604), (12, 0.8259108126163482), (13, 0.8691954791545868), (14, 0.8911743104457855), (15, 0.8889553964138031), (16, 0.9333120107650756), (17, 0.9507725238800049), (18, 0.9851505756378174), (19, 1.0566859900951386), (20, 0.9832888126373291)]\n",
      "INFO flwr 2024-07-24 05:26:04,031 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-07-24 05:26:04,032 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 67.95566502463055), (2, 67.95566502463053), (3, 67.95566502463053), (4, 67.95566502463055), (5, 65.11083743842364), (6, 61.921182266009865), (7, 64.4088669950739), (8, 62.99261083743843), (9, 64.76600985221674), (10, 67.6231527093596), (11, 67.99261083743843), (12, 69.4088669950739), (13, 67.26600985221675), (14, 68.34975369458128), (15, 66.564039408867), (16, 67.6231527093596), (17, 67.64778325123153), (18, 68.33743842364532), (19, 68.3497536945813), (20, 66.93349753694582)]}\n",
      "INFO flwr 2024-07-24 05:26:04,033 | app.py:228 | app_fit: losses_centralized [(0, 0.6918965632265265), (1, 0.6523008807138964), (2, 0.654758870601654), (3, 0.6380183290351521), (4, 0.6458223245360635), (5, 0.6118300340392373), (6, 0.6617710529403253), (7, 0.7338515366004272), (8, 0.7946386493065141), (9, 0.756576085801829), (10, 0.7342284294691953), (11, 0.7459455730224197), (12, 0.7624565901404078), (13, 0.8462171556258743), (14, 0.8497073252431371), (15, 0.8507100167599592), (16, 0.9239390754902904), (17, 0.9248961626806043), (18, 0.9564968906342983), (19, 0.9629694619639353), (20, 0.9463489573787559)]\n",
      "INFO flwr 2024-07-24 05:26:04,034 | app.py:229 | app_fit: metrics_centralized {'accuracy': [(0, 64.77272727272727), (1, 65.3409090909091), (2, 65.3409090909091), (3, 65.3409090909091), (4, 65.3409090909091), (5, 66.19318181818183), (6, 63.92045454545454), (7, 65.625), (8, 65.9090909090909), (9, 64.48863636363636), (10, 63.35227272727273), (11, 63.92045454545454), (12, 63.63636363636363), (13, 63.92045454545454), (14, 62.5), (15, 61.36363636363637), (16, 63.63636363636363), (17, 63.92045454545454), (18, 62.5), (19, 64.77272727272727), (20, 63.06818181818182)]}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Time = 4200.409300327301 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "client_resources = None\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_gpus\": 1}\n",
    "\n",
    "model_save = model_save\n",
    "path_yaml = yaml_path\n",
    "path_roc = roc_path\n",
    "results_save = save_results\n",
    "path_matrix = matrix_path\n",
    "batch_size = batch_size\n",
    "he = he\n",
    "secret_path = 'secret.pkl'\n",
    "server_path = 'secret.pkl'\n",
    "path_crypted = 'server.pkl'\n",
    "\n",
    "print(\"Start simulation\")\n",
    "start_simulation = time.time()\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=number_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources\n",
    ")\n",
    "print(f\"Simulation Time = {time.time() - start_simulation} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
