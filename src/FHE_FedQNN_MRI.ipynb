{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash\n",
    "\n",
    "# kaggle datasets download -d masoudnickparvar/brain-tumor-mri-dataset\n",
    "# mkdir data data/MRI\n",
    "# unzip brain-tumor-mri-dataset.zip -d data/MRI\n",
    "# rm brain-tumor-mri-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from collections import OrderedDict\n",
    "from typing import (\n",
    "    List, Tuple, Dict, Optional, Callable, Union\n",
    ")\n",
    "import tenseal as ts\n",
    "\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import flwr as fl\n",
    "from flwr.common import (\n",
    "    Metrics, EvaluateIns, EvaluateRes, FitIns, FitRes, MetricsAggregationFn, \n",
    "    Scalar, logger, ndarrays_to_parameters_custom, parameters_to_ndarrays_custom,\n",
    "    Parameters, NDArrays\n",
    ")\n",
    "from flwr.server.client_proxy import ClientProxy\n",
    "from flwr.server.client_manager import ClientManager\n",
    "from flwr.server.strategy.aggregate import weighted_loss_avg\n",
    "from logging import WARNING\n",
    "import pennylane as qml\n",
    "\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation of FHE Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it exists\n"
     ]
    }
   ],
   "source": [
    "def combo_keys(client_path=\"secret.pkl\", server_path=\"server_key.pkl\"):\n",
    "    \"\"\"\n",
    "    To create the public/private keys combination\n",
    "    args:\n",
    "        client_path: path to save the secret key (str)\n",
    "        server_path: path to save the server public key (str)\n",
    "    \"\"\"\n",
    "    context_client = security.context()\n",
    "    security.write_query(client_path, {\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "    security.write_query(server_path, {\"contexte\": context_client.serialize()})\n",
    "\n",
    "    _, context_client = security.read_query(client_path)\n",
    "    _, context_server = security.read_query(server_path)\n",
    "\n",
    "    context_client = ts.context_from(context_client)\n",
    "    context_server = ts.context_from(context_server)\n",
    "    print(\"Is the client context private?\", (\"Yes\" if context_client.is_private() else \"No\"))\n",
    "    print(\"Is the server context private?\", (\"Yes\" if context_server.is_private() else \"No\"))\n",
    "\n",
    "\n",
    "secret_path = \"secret.pkl\"\n",
    "public_path = \"server_key.pkl\"\n",
    "if os.path.exists(secret_path):\n",
    "    print(\"it exists\")\n",
    "    _, context_client = security.read_query(secret_path)\n",
    "\n",
    "else:\n",
    "    combo_keys(client_path=secret_path, server_path=public_path)\n",
    "\n",
    "n_qubits = 4\n",
    "n_layers = 6\n",
    "weight_shapes = {\"weights\": (n_layers, n_qubits)}       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit.torch\", wires=n_qubits)\n",
    "    \n",
    "@qml.qnode(dev, interface='torch')\n",
    "def quantum_net(inputs, weights):\n",
    "    qml.AngleEmbedding(inputs, wires=range(n_qubits)) \n",
    "    qml.BasicEntanglerLayers(weights,wires=range(n_qubits))\n",
    "    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\"\n",
    "    A simple CNN model\n",
    "\n",
    "    Args:\n",
    "        num_classes: An integer indicating the number of classes in the dataset.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes=10) -> None:\n",
    "        super(Net, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 56 * 56, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(128, n_qubits),\n",
    "            qml.qnn.TorchLayer(quantum_net, weight_shapes=weight_shapes),\n",
    "            nn.Linear(n_qubits, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass of the neural network\n",
    "        \"\"\"\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FlowerClient class for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FlowerClient(fl.client.NumPyClient):\n",
    "    def __init__(self, cid, net, trainloader, valloader, device, batch_size, save_results, matrix_path, roc_path,\n",
    "                 yaml_path, he, classes, context_client):\n",
    "        self.net = net\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = valloader\n",
    "        self.cid = cid\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "        self.save_results = save_results\n",
    "        self.matrix_path = matrix_path\n",
    "        self.roc_path = roc_path\n",
    "        self.yaml_path = yaml_path\n",
    "        self.he = he\n",
    "        self.classes = classes\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def get_parameters(self, config):\n",
    "        print(f\"[Client {self.cid}] get_parameters\")\n",
    "        return get_parameters2(self.net, self.context_client)\n",
    "\n",
    "    def fit(self, parameters, config):\n",
    "        server_round = config['server_round']\n",
    "        local_epochs = config['local_epochs']\n",
    "        lr = float(config[\"learning_rate\"])\n",
    "\n",
    "        print(f'[Client {self.cid}, round {server_round}] fit, config: {config}')\n",
    "\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        criterion = torch.nn.CrossEntropyLoss()\n",
    "        optimizer = torch.optim.SGD(self.net.parameters(), lr=lr, momentum=0.9)\n",
    "\n",
    "        results = engine.train(self.net, self.trainloader, self.valloader, optimizer=optimizer, loss_fn=criterion,\n",
    "                               epochs=local_epochs, device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            save_graphs(self.save_results, local_epochs, results, f\"_Client {self.cid}\")\n",
    "\n",
    "        return get_parameters2(self.net, self.context_client), len(self.trainloader), {}\n",
    "\n",
    "    def evaluate(self, parameters, config):\n",
    "        print(f\"[Client {self.cid}] evaluate, config: {config}\")\n",
    "        set_parameters(self.net, parameters, self.context_client)\n",
    "\n",
    "        loss, accuracy, y_pred, y_true, y_proba = engine.test(self.net, self.valloader,\n",
    "                                                              loss_fn=torch.nn.CrossEntropyLoss(), device=self.device)\n",
    "\n",
    "        if self.save_results:\n",
    "            os.makedirs(self.save_results, exist_ok=True)\n",
    "            if self.matrix_path:\n",
    "                save_matrix(y_true, y_pred, self.save_results + self.matrix_path, self.classes)\n",
    "            if self.roc_path:\n",
    "                save_roc(y_true, y_proba, self.save_results + self.roc_path, len(self.classes))\n",
    "\n",
    "        return float(loss), len(self.valloader), {\"accuracy\": float(accuracy)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_common function to set up the Flower client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def client_common(cid, model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                  batch_size, trainloaders, valloaders, DEVICE, CLASSES,\n",
    "                  he=False, secret_path=\"\", server_path=\"\"):\n",
    "    trainloader = trainloaders[int(cid)]\n",
    "    valloader = valloaders[int(cid)]\n",
    "\n",
    "    context_client = None\n",
    "    net = Net(num_classes=len(CLASSES)).to(DEVICE)\n",
    "\n",
    "    if he:\n",
    "        print(\"Run with homomorphic encryption\")\n",
    "        if os.path.exists(secret_path):\n",
    "            with open(secret_path, 'rb') as f:\n",
    "                query = pickle.load(f)\n",
    "            context_client = ts.context_from(query[\"contexte\"])\n",
    "        else:\n",
    "            context_client = security.context()\n",
    "            with open(secret_path, 'wb') as f:\n",
    "                encode = pickle.dumps({\"contexte\": context_client.serialize(save_secret_key=True)})\n",
    "                f.write(encode)\n",
    "        secret_key = context_client.secret_key()\n",
    "    else:\n",
    "        print(\"Run WITHOUT homomorphic encryption\")\n",
    "\n",
    "    if os.path.exists(model_save):\n",
    "        print(\" To get the checkpoint\")\n",
    "        checkpoint = torch.load(model_save, map_location=DEVICE)['model_state_dict']\n",
    "        if he:\n",
    "            print(\"to decrypt model\")\n",
    "            server_query, server_context = security.read_query(server_path)\n",
    "            server_context = ts.context_from(server_context)\n",
    "            for name in checkpoint:\n",
    "                print(name)\n",
    "                checkpoint[name] = torch.tensor(\n",
    "                    security.deserialized_layer(name, server_query[name], server_context).decrypt(secret_key)\n",
    "                )\n",
    "        net.load_state_dict(checkpoint)\n",
    "\n",
    "    return FlowerClient(cid, net, trainloader, valloader, device=DEVICE, batch_size=batch_size,\n",
    "                        matrix_path=path_matrix, roc_path=path_roc, save_results=results_save, yaml_path=path_yaml,\n",
    "                        he=he, context_client=context_client, classes=CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define utility functions for federated learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_average(metrics: List[Tuple[int, Metrics]]) -> Metrics:\n",
    "    accuracies = [num_examples * m[\"accuracy\"] for num_examples, m in metrics]\n",
    "    examples = [num_examples for num_examples, _ in metrics]\n",
    "    return {\"accuracy\": sum(accuracies) / sum(examples)}\n",
    "\n",
    "def evaluate2(server_round: int, parameters: NDArrays,\n",
    "              config: Dict[str, Scalar]) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "    set_parameters(central, parameters)\n",
    "    loss, accuracy, y_pred, y_true, y_proba = engine.test(central, testloader, loss_fn=torch.nn.CrossEntropyLoss(),\n",
    "                                                          device=DEVICE)\n",
    "    print(f\"Server-side evaluation loss {loss} / accuracy {accuracy}\")\n",
    "    return loss, {\"accuracy\": accuracy}\n",
    "\n",
    "def get_on_fit_config_fn(epoch=2, lr=0.001, batch_size=32) -> Callable[[int], Dict[str, str]]:\n",
    "    def fit_config(server_round: int) -> Dict[str, str]:\n",
    "        config = {\n",
    "            \"learning_rate\": str(lr),\n",
    "            \"batch_size\": str(batch_size),\n",
    "            \"server_round\": server_round,\n",
    "            \"local_epochs\": epoch\n",
    "        }\n",
    "        return config\n",
    "    return fit_config\n",
    "\n",
    "def aggreg_fit_checkpoint(server_round, aggregated_parameters, central_model, path_checkpoint,\n",
    "                          context_client=None, server_path=\"\"):\n",
    "    if aggregated_parameters is not None:\n",
    "        print(f\"Saving round {server_round} aggregated_parameters...\")\n",
    "        aggregated_ndarrays: List[np.ndarray] = parameters_to_ndarrays_custom(aggregated_parameters, context_client)\n",
    "        if context_client:\n",
    "            def serialized(key, matrix):\n",
    "                if key == 'fc3.weight':\n",
    "                    return matrix.serialize()\n",
    "                else:\n",
    "                    return matrix\n",
    "            server_response = {\n",
    "                **{key: serialized(key, aggregated_ndarrays[i]) for i, key in enumerate(central_model.state_dict().keys())},\n",
    "                \"contexte\": server_context.serialize()\n",
    "            }\n",
    "            security.write_query(server_path, server_response)\n",
    "        else:\n",
    "            params_dict = zip(central_model.state_dict().keys(), aggregated_ndarrays)\n",
    "            state_dict = OrderedDict({k: torch.tensor(v) for k, v in params_dict})\n",
    "            central_model.load_state_dict(state_dict, strict=True)\n",
    "            if path_checkpoint:\n",
    "                torch.save({\n",
    "                    'model_state_dict': central_model.state_dict(),\n",
    "                }, path_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the FedCustom strategy class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Strategy from scratch with the same sampling of the clients as it is in FedAvg\n",
    "# and then change the configuration dictionary\n",
    "class FedCustom(fl.server.strategy.Strategy):\n",
    "    def __init__(\n",
    "            self,\n",
    "            fraction_fit: float = 1.0,\n",
    "            fraction_evaluate: float = 1.0,\n",
    "            min_fit_clients: int = 2,\n",
    "            min_evaluate_clients: int = 2,\n",
    "            min_available_clients: int = 2,\n",
    "            evaluate_fn: Optional[\n",
    "                    Callable[[int, NDArrays, Dict[str, Scalar]], Optional[Tuple[float, Dict[str, Scalar]]]]\n",
    "                ] = None,\n",
    "            on_fit_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            on_evaluate_config_fn: Optional[Callable[[int], Dict[str, Scalar]]] = None,\n",
    "            accept_failures: bool = True,\n",
    "            initial_parameters: Optional[Parameters] = None,\n",
    "            fit_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            evaluate_metrics_aggregation_fn: Optional[MetricsAggregationFn] = None,\n",
    "            context_client=None\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.fraction_fit = fraction_fit\n",
    "        self.fraction_evaluate = fraction_evaluate\n",
    "        self.min_fit_clients = min_fit_clients\n",
    "        self.min_evaluate_clients = min_evaluate_clients\n",
    "        self.min_available_clients = min_available_clients\n",
    "        self.evaluate_fn = evaluate_fn\n",
    "        self.on_fit_config_fn = on_fit_config_fn\n",
    "        self.on_evaluate_config_fn = on_evaluate_config_fn,\n",
    "        self.accept_failures = accept_failures\n",
    "        self.initial_parameters = initial_parameters\n",
    "        self.fit_metrics_aggregation_fn = fit_metrics_aggregation_fn\n",
    "        self.evaluate_metrics_aggregation_fn = evaluate_metrics_aggregation_fn\n",
    "        self.context_client = context_client\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        return f\"FedCustom (accept_failures={self.accept_failures})\"\n",
    "\n",
    "    def initialize_parameters(\n",
    "        self, client_manager: ClientManager\n",
    "    ) -> Optional[Parameters]:\n",
    "        \"\"\"Initialize global model parameters.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        initial_parameters = self.initial_parameters\n",
    "        self.initial_parameters = None  # Don't keep initial parameters in memory\n",
    "        return initial_parameters\n",
    "\n",
    "    def num_fit_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Return sample size and required number of clients.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_fit)\n",
    "        return max(num_clients, self.min_fit_clients), self.min_available_clients\n",
    "\n",
    "    def configure_fit(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, FitIns]]:\n",
    "        \"\"\"Configure the next round of training.\"\"\"\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_fit_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "        # Create custom configs\n",
    "        n_clients = len(clients)\n",
    "        half_clients = n_clients // 2\n",
    "        # Custom fit config function provided\n",
    "        standard_lr = lr\n",
    "        higher_lr = 0.003\n",
    "        config = {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "        if self.on_fit_config_fn is not None:\n",
    "            # Custom fit config function provided\n",
    "            config = self.on_fit_config_fn(server_round)\n",
    "\n",
    "        # fit_ins = FitIns(parameters, config)\n",
    "        # Return client/config pairs\n",
    "        fit_configurations = []\n",
    "        for idx, client in enumerate(clients):\n",
    "            config[\"learning_rate\"] = standard_lr if idx < half_clients else higher_lr\n",
    "            \"\"\"\n",
    "            Each pair of (ClientProxy, FitRes) constitutes \n",
    "            a successful update from one of the previously selected clients.\n",
    "            \"\"\"\n",
    "            fit_configurations.append(\n",
    "                (\n",
    "                    client,\n",
    "                    FitIns(\n",
    "                        parameters,\n",
    "                        config\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        # Successful updates from the previously selected and configured clients\n",
    "        return fit_configurations\n",
    "\n",
    "    def aggregate_fit(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, FitRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, FitRes], BaseException]],\n",
    "    ) -> Tuple[Optional[Parameters], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate fit results using weighted average. (each round)\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Convert results parameters --> array matrix\n",
    "        weights_results = [\n",
    "            (parameters_to_ndarrays_custom(fit_res.parameters, self.context_client), fit_res.num_examples)\n",
    "            for _, fit_res in results\n",
    "        ]\n",
    "\n",
    "        # Aggregate parameters using weighted average between the clients and convert back to parameters object (bytes)\n",
    "        parameters_aggregated = ndarrays_to_parameters_custom(aggregate_custom(weights_results))\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.fit_metrics_aggregation_fn:\n",
    "            fit_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.fit_metrics_aggregation_fn(fit_metrics)\n",
    "\n",
    "        elif server_round == 1:  # Only log this warning once\n",
    "            logger.log(WARNING, \"No fit_metrics_aggregation_fn provided\")\n",
    "\n",
    "        # Same function as SaveModelStrategy(fl.server.strategy.FedAvg)\n",
    "        \"\"\"Aggregate model weights using weighted average and store checkpoint\"\"\"\n",
    "        aggreg_fit_checkpoint(server_round, parameters_aggregated, central, model_save,\n",
    "                              self.context_client, path_crypted)\n",
    "        return parameters_aggregated, metrics_aggregated\n",
    "\n",
    "    def num_evaluation_clients(self, num_available_clients: int) -> Tuple[int, int]:\n",
    "        \"\"\"Use a fraction of available clients for evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        num_clients = int(num_available_clients * self.fraction_evaluate)\n",
    "        return max(num_clients, self.min_evaluate_clients), self.min_available_clients\n",
    "\n",
    "    def configure_evaluate(\n",
    "        self, server_round: int, parameters: Parameters, client_manager: ClientManager\n",
    "    ) -> List[Tuple[ClientProxy, EvaluateIns]]:\n",
    "        \"\"\"Configure the next round of evaluation.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        # Do not configure federated evaluation if fraction eval is 0.\n",
    "        if self.fraction_evaluate == 0.0:\n",
    "            return []\n",
    "\n",
    "        # Parameters and config\n",
    "        config = {}  # {\"server_round\": server_round, \"local_epochs\": 1}\n",
    "\n",
    "        evaluate_ins = EvaluateIns(parameters, config)\n",
    "\n",
    "        # Sample clients\n",
    "        sample_size, min_num_clients = self.num_evaluation_clients(\n",
    "            client_manager.num_available()\n",
    "        )\n",
    "\n",
    "        clients = client_manager.sample(\n",
    "            num_clients=sample_size, min_num_clients=min_num_clients\n",
    "        )\n",
    "\n",
    "        # Return client/config pairs\n",
    "        # Each pair of (ClientProxy, FitRes) constitutes a successful update from one of the previously selected clients\n",
    "        return [(client, evaluate_ins) for client in clients]\n",
    "\n",
    "    def aggregate_evaluate(\n",
    "        self,\n",
    "        server_round: int,\n",
    "        results: List[Tuple[ClientProxy, EvaluateRes]],\n",
    "        failures: List[Union[Tuple[ClientProxy, EvaluateRes], BaseException]],\n",
    "    ) -> Tuple[Optional[float], Dict[str, Scalar]]:\n",
    "        \"\"\"Aggregate evaluation losses using weighted average.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if not results:\n",
    "            return None, {}\n",
    "\n",
    "        # Do not aggregate if there are failures and failures are not accepted\n",
    "        if not self.accept_failures and failures:\n",
    "            return None, {}\n",
    "\n",
    "        # Aggregate loss\n",
    "        loss_aggregated = weighted_loss_avg(\n",
    "            [\n",
    "                (evaluate_res.num_examples, evaluate_res.loss)\n",
    "                for _, evaluate_res in results\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        metrics_aggregated = {}\n",
    "        # Aggregate custom metrics if aggregation fn was provided\n",
    "        if self.evaluate_metrics_aggregation_fn:\n",
    "            eval_metrics = [(res.num_examples, res.metrics) for _, res in results]\n",
    "            metrics_aggregated = self.evaluate_metrics_aggregation_fn(eval_metrics)\n",
    "\n",
    "        # Only log this warning once\n",
    "        elif server_round == 1:\n",
    "            logger.log(WARNING, \"No evaluate_metrics_aggregation_fn provided\")\n",
    "\n",
    "        return loss_aggregated, metrics_aggregated\n",
    "\n",
    "    def evaluate(\n",
    "        self, server_round: int, parameters: Parameters\n",
    "    ) -> Optional[Tuple[float, Dict[str, Scalar]]]:\n",
    "        \"\"\"Evaluate global model parameters using an evaluation function.\"\"\"\n",
    "        # Same function as FedAvg(Strategy)\n",
    "        if self.evaluate_fn is None:\n",
    "            # Let's assume we won't perform the global model evaluation on the server side.\n",
    "            return None\n",
    "\n",
    "        # if we have a global model evaluation on the server side :\n",
    "        parameters_ndarrays = parameters_to_ndarrays_custom(parameters, self.context_client)\n",
    "        eval_res = self.evaluate_fn(server_round, parameters_ndarrays, {})\n",
    "\n",
    "        # if you haven't results\n",
    "        if eval_res is None:\n",
    "            return None\n",
    "\n",
    "        loss, metrics = eval_res\n",
    "        return loss, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the federated learning strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up your variables directly\n",
    "he = True\n",
    "data_path = 'data/'\n",
    "dataset = 'MRI'\n",
    "yaml_path = './results/FL/results.yml'\n",
    "seed = 42\n",
    "num_workers = 0\n",
    "max_epochs = 5\n",
    "batch_size = 32\n",
    "length = 224\n",
    "split = 10\n",
    "device = 'gpu'\n",
    "number_clients = 10\n",
    "save_results = 'results/FL/'\n",
    "matrix_path = 'confusion_matrix.png'\n",
    "roc_path = 'roc.png'\n",
    "model_save = 'MRI_FHE.pt'\n",
    "min_fit_clients = 10\n",
    "min_avail_clients = 10\n",
    "min_eval_clients = 10\n",
    "rounds = 2\n",
    "frac_fit = 1.0\n",
    "frac_eval = 0.5\n",
    "lr = 1e-4\n",
    "path_public_key = 'server_key.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get public key :  server_key.pkl\n"
     ]
    }
   ],
   "source": [
    "print(\"get public key : \", path_public_key)\n",
    "_, server_context = security.read_query(path_public_key)\n",
    "server_context = ts.context_from(server_context)\n",
    "DEVICE = torch.device(choice_device(device))\n",
    "CLASSES = classes_string(dataset)\n",
    "central = Net(num_classes=len(CLASSES)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = FedCustom(\n",
    "    fraction_fit=frac_fit,\n",
    "    fraction_evaluate=frac_eval,\n",
    "    min_fit_clients=min_fit_clients,\n",
    "    min_evaluate_clients=min_eval_clients if min_eval_clients else number_clients // 2,\n",
    "    min_available_clients=min_avail_clients,\n",
    "    evaluate_metrics_aggregation_fn=weighted_average,\n",
    "    initial_parameters=ndarrays_to_parameters_custom(get_parameters2(central)),\n",
    "    evaluate_fn=None if he else evaluate2,\n",
    "    on_fit_config_fn=get_on_fit_config_fn(epoch=max_epochs, batch_size=batch_size),\n",
    "    context_client=server_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRI\n",
      "The training set is created for the classes : ['glioma', 'meningioma', 'notumor', 'pituitary']\n"
     ]
    }
   ],
   "source": [
    "trainloaders, valloaders, testloader = data_setup.load_datasets(num_clients=number_clients,\n",
    "                                                                batch_size=batch_size,\n",
    "                                                                resize=224,\n",
    "                                                                seed=seed,\n",
    "                                                                num_workers=num_workers,\n",
    "                                                                splitter=10,\n",
    "                                                                dataset=dataset,  # Use the specified dataset\n",
    "                                                                data_path=data_path,\n",
    "                                                                data_path_val=None)  # Use the same path for validation data\n",
    "\n",
    "def client_fn(cid: str) -> FlowerClient:\n",
    "    return client_common(cid,\n",
    "                         model_save, path_yaml, path_roc, results_save, path_matrix,\n",
    "                         batch_size, trainloaders, valloaders, DEVICE, CLASSES, he, secret_path, server_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the client_fn function and set up the simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO flwr 2024-07-14 03:02:16,078 | app.py:145 | Starting Flower simulation, config: ServerConfig(num_rounds=2, round_timeout=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flwr 1.5.0\n",
      "numpy 1.24.3\n",
      "torch 2.3.1+cu121\n",
      "torchvision 0.18.1+cu121\n",
      "Training on cuda:0\n",
      "Start simulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-14 03:02:19,164\tINFO worker.py:1788 -- Started a local Ray instance.\n",
      "INFO flwr 2024-07-14 03:02:22,666 | app.py:179 | Flower VCE: Ray initialized with resources: {'memory': 7887008564.0, 'node:192.168.0.156': 1.0, 'accelerator_type:G': 1.0, 'object_store_memory': 3943504281.0, 'GPU': 1.0, 'CPU': 20.0, 'node:__internal_head__': 1.0}\n",
      "INFO flwr 2024-07-14 03:02:22,667 | server.py:89 | Initializing global parameters\n",
      "INFO flwr 2024-07-14 03:02:22,667 | server.py:272 | Using initial parameters provided by strategy\n",
      "INFO flwr 2024-07-14 03:02:22,668 | server.py:91 | Evaluating initial parameters\n",
      "INFO flwr 2024-07-14 03:02:22,668 | server.py:104 | FL starting\n",
      "DEBUG flwr 2024-07-14 03:02:22,668 | server.py:222 | fit_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 9, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4050 | Train_acc: 24.0809 % | Validation_loss: 1.3938 | Validation_acc: 20.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:03<00:13,  3.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3788 | Train_acc: 23.1618 % | Validation_loss: 1.3590 | Validation_acc: 20.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:08,  2.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3517 | Train_acc: 29.5956 % | Validation_loss: 1.3234 | Validation_acc: 38.7500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:08<00:05,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3178 | Train_acc: 36.5809 % | Validation_loss: 1.3065 | Validation_acc: 53.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.2945 | Train_acc: 47.0588 % | Validation_loss: 1.2528 | Validation_acc: 63.2500 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:13<00:00,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.337860107421875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 5.4836273193359375e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 0, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4044 | Train_acc: 24.6324 % | Validation_loss: 1.4059 | Validation_acc: 23.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3870 | Train_acc: 24.6324 % | Validation_loss: 1.3862 | Validation_acc: 23.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3612 | Train_acc: 26.4706 % | Validation_loss: 1.3715 | Validation_acc: 24.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3299 | Train_acc: 38.4191 % | Validation_loss: 1.3479 | Validation_acc: 47.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3116 | Train_acc: 39.8897 % | Validation_loss: 1.3105 | Validation_acc: 39.6250 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.86102294921875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 1, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4050 | Train_acc: 22.9779 % | Validation_loss: 1.4119 | Validation_acc: 21.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3698 | Train_acc: 23.8971 % | Validation_loss: 1.3898 | Validation_acc: 20.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3407 | Train_acc: 31.9853 % | Validation_loss: 1.3728 | Validation_acc: 33.6250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3160 | Train_acc: 37.3162 % | Validation_loss: 1.3493 | Validation_acc: 26.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.2943 | Train_acc: 40.8088 % | Validation_loss: 1.3367 | Validation_acc: 45.0000 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.86102294921875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 2, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4027 | Train_acc: 22.4265 % | Validation_loss: 1.3871 | Validation_acc: 26.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3776 | Train_acc: 29.2279 % | Validation_loss: 1.3683 | Validation_acc: 26.0625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3416 | Train_acc: 32.9044 % | Validation_loss: 1.3305 | Validation_acc: 37.1875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3088 | Train_acc: 32.3529 % | Validation_loss: 1.3039 | Validation_acc: 39.8750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.2698 | Train_acc: 52.5735 % | Validation_loss: 1.3141 | Validation_acc: 42.8125 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.337860107421875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 9.5367431640625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 7, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4078 | Train_acc: 21.8750 % | Validation_loss: 1.4100 | Validation_acc: 16.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:11,  2.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3780 | Train_acc: 26.1029 % | Validation_loss: 1.3835 | Validation_acc: 36.7500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3536 | Train_acc: 26.2868 % | Validation_loss: 1.3463 | Validation_acc: 22.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3301 | Train_acc: 30.5147 % | Validation_loss: 1.3248 | Validation_acc: 22.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.2903 | Train_acc: 43.0147 % | Validation_loss: 1.2787 | Validation_acc: 59.2500 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.0994415283203125e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 6, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.3875 | Train_acc: 29.0441 % | Validation_loss: 1.4112 | Validation_acc: 19.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:11,  2.75s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3982 | Train_acc: 23.5294 % | Validation_loss: 1.3956 | Validation_acc: 19.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3696 | Train_acc: 29.2279 % | Validation_loss: 1.3695 | Validation_acc: 19.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3416 | Train_acc: 26.2868 % | Validation_loss: 1.3336 | Validation_acc: 21.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3116 | Train_acc: 30.5147 % | Validation_loss: 1.3055 | Validation_acc: 27.8125 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.6226043701171875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 8, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4105 | Train_acc: 22.9779 % | Validation_loss: 1.4074 | Validation_acc: 17.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3841 | Train_acc: 22.9779 % | Validation_loss: 1.3667 | Validation_acc: 17.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3499 | Train_acc: 32.3529 % | Validation_loss: 1.3556 | Validation_acc: 25.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3104 | Train_acc: 34.5588 % | Validation_loss: 1.3302 | Validation_acc: 19.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3116 | Train_acc: 33.2721 % | Validation_loss: 1.2895 | Validation_acc: 40.5000 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.0994415283203125e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 5, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4038 | Train_acc: 23.1618 % | Validation_loss: 1.4133 | Validation_acc: 15.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.69s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3698 | Train_acc: 25.0000 % | Validation_loss: 1.3940 | Validation_acc: 34.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3564 | Train_acc: 29.4118 % | Validation_loss: 1.3627 | Validation_acc: 42.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3412 | Train_acc: 36.9485 % | Validation_loss: 1.3569 | Validation_acc: 15.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3128 | Train_acc: 33.4559 % | Validation_loss: 1.3162 | Validation_acc: 49.0000 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.6226043701171875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 4, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4049 | Train_acc: 24.2647 % | Validation_loss: 1.3960 | Validation_acc: 20.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:11,  2.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3839 | Train_acc: 21.5074 % | Validation_loss: 1.3476 | Validation_acc: 20.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3514 | Train_acc: 33.6397 % | Validation_loss: 1.3339 | Validation_acc: 20.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3318 | Train_acc: 27.0221 % | Validation_loss: 1.3209 | Validation_acc: 20.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3046 | Train_acc: 25.7353 % | Validation_loss: 1.3225 | Validation_acc: 24.0625 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.6226043701171875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 3, round 1] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 1, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.4137 | Train_acc: 23.3456 % | Validation_loss: 1.4196 | Validation_acc: 19.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3866 | Train_acc: 28.8603 % | Validation_loss: 1.3980 | Validation_acc: 19.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.3857 | Train_acc: 23.3456 % | Validation_loss: 1.3871 | Validation_acc: 19.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3679 | Train_acc: 23.3456 % | Validation_loss: 1.3655 | Validation_acc: 19.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.56s/it]\n",
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.57s/it]\n",
      "DEBUG flwr 2024-07-14 03:04:47,784 | server.py:236 | fit_round 1 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3603 | Train_acc: 26.1029 % | Validation_loss: 1.3331 | Validation_acc: 26.2500 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.86102294921875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING flwr 2024-07-14 03:04:48,421 | 3890383987.py:131 | No fit_metrics_aggregation_fn provided\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving round 1 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-14 03:04:48,850 | server.py:173 | evaluate_round 1: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:262: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure(figsize=(12, 7))\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:312: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m   plt.figure()\n",
      "DEBUG flwr 2024-07-14 03:05:04,325 | server.py:187 | evaluate_round 1 received 10 results and 0 failures\n",
      "DEBUG flwr 2024-07-14 03:05:04,325 | server.py:222 | fit_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 2, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2857 | Train_acc: 53.8603 % | Validation_loss: 1.3091 | Validation_acc: 40.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2733 | Train_acc: 53.4926 % | Validation_loss: 1.2734 | Validation_acc: 42.5625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2194 | Train_acc: 64.3382 % | Validation_loss: 1.2321 | Validation_acc: 62.1875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.1784 | Train_acc: 67.6471 % | Validation_loss: 1.1616 | Validation_acc: 62.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1460 | Train_acc: 67.0956 % | Validation_loss: 1.2071 | Validation_acc: 45.0000 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.51s/it]\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m /home/siddhant/QFML-QF-2024/src/utils/common.py:393: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m   plt.figure()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.6226043701171875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 4, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2895 | Train_acc: 50.0000 % | Validation_loss: 1.2519 | Validation_acc: 73.9375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:09,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2481 | Train_acc: 67.2794 % | Validation_loss: 1.2158 | Validation_acc: 64.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:04<00:07,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2192 | Train_acc: 63.6029 % | Validation_loss: 1.2239 | Validation_acc: 57.6875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:04,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.2071 | Train_acc: 60.6618 % | Validation_loss: 1.1945 | Validation_acc: 74.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:09<00:02,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1552 | Train_acc: 67.2794 % | Validation_loss: 1.1886 | Validation_acc: 60.5625 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.86102294921875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 7, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2789 | Train_acc: 56.2500 % | Validation_loss: 1.3406 | Validation_acc: 18.5000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2732 | Train_acc: 51.6544 % | Validation_loss: 1.2620 | Validation_acc: 53.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2196 | Train_acc: 67.6471 % | Validation_loss: 1.1983 | Validation_acc: 72.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.1466 | Train_acc: 72.6103 % | Validation_loss: 1.1414 | Validation_acc: 76.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1216 | Train_acc: 71.1397 % | Validation_loss: 1.0724 | Validation_acc: 77.9375 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.0994415283203125e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 0, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2946 | Train_acc: 43.9338 % | Validation_loss: 1.2927 | Validation_acc: 42.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:09,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2522 | Train_acc: 59.3750 % | Validation_loss: 1.3144 | Validation_acc: 35.1875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:04<00:07,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2999 | Train_acc: 43.1985 % | Validation_loss: 1.2621 | Validation_acc: 41.1875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:04,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.2354 | Train_acc: 56.9853 % | Validation_loss: 1.2120 | Validation_acc: 48.3125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:09<00:02,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1999 | Train_acc: 58.2721 % | Validation_loss: 1.1810 | Validation_acc: 55.8750 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.6226043701171875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 1, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2795 | Train_acc: 51.1029 % | Validation_loss: 1.2867 | Validation_acc: 47.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2416 | Train_acc: 58.0882 % | Validation_loss: 1.2512 | Validation_acc: 62.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2024 | Train_acc: 62.1324 % | Validation_loss: 1.2918 | Validation_acc: 52.5625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.3401 | Train_acc: 39.1544 % | Validation_loss: 1.3034 | Validation_acc: 40.7500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.2651 | Train_acc: 48.5294 % | Validation_loss: 1.2245 | Validation_acc: 59.2500 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.51s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.86102294921875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 1.6689300537109375e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 5, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2948 | Train_acc: 39.3382 % | Validation_loss: 1.3055 | Validation_acc: 52.5625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.3048 | Train_acc: 46.3235 % | Validation_loss: 1.2990 | Validation_acc: 66.3750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2755 | Train_acc: 44.6691 % | Validation_loss: 1.2667 | Validation_acc: 50.5625 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.2207 | Train_acc: 57.9044 % | Validation_loss: 1.2444 | Validation_acc: 60.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1709 | Train_acc: 71.3235 % | Validation_loss: 1.1922 | Validation_acc: 65.6875 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.384185791015625e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 9.5367431640625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 9, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2777 | Train_acc: 56.6176 % | Validation_loss: 1.2601 | Validation_acc: 64.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2451 | Train_acc: 62.3162 % | Validation_loss: 1.2282 | Validation_acc: 63.2500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2067 | Train_acc: 65.4412 % | Validation_loss: 1.1482 | Validation_acc: 69.6875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.54s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.1530 | Train_acc: 70.0368 % | Validation_loss: 1.1150 | Validation_acc: 65.6875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.0878 | Train_acc: 74.4485 % | Validation_loss: 1.0402 | Validation_acc: 72.3750 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 2.6226043701171875e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 3, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2856 | Train_acc: 50.9191 % | Validation_loss: 1.2825 | Validation_acc: 37.1875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.56s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2587 | Train_acc: 54.5956 % | Validation_loss: 1.2472 | Validation_acc: 55.4375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2162 | Train_acc: 60.6618 % | Validation_loss: 1.2384 | Validation_acc: 51.4375 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:05,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.1760 | Train_acc: 64.7059 % | Validation_loss: 1.1763 | Validation_acc: 59.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:10<00:02,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1360 | Train_acc: 71.3235 % | Validation_loss: 1.1407 | Validation_acc: 62.1250 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.5762786865234375e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 9.5367431640625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 8, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2882 | Train_acc: 42.4632 % | Validation_loss: 1.2698 | Validation_acc: 53.6875 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:10,  2.52s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2402 | Train_acc: 60.6618 % | Validation_loss: 1.2244 | Validation_acc: 53.8750 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:05<00:07,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2067 | Train_acc: 61.3971 % | Validation_loss: 1.2386 | Validation_acc: 51.0000 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:04,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.1690 | Train_acc: 63.7868 % | Validation_loss: 1.1343 | Validation_acc: 70.8125 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:09<00:02,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.1155 | Train_acc: 69.8529 % | Validation_loss: 1.0664 | Validation_acc: 73.9375 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.0994415283203125e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m [Client 6, round 2] fit, config: {'learning_rate': 0.003, 'batch_size': '32', 'server_round': 2, 'local_epochs': 5}\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|\u001b[34m          \u001b[0m| 0/5 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 1 \tTrain_loss: 1.2936 | Train_acc: 43.1985 % | Validation_loss: 1.2793 | Validation_acc: 60.1250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|\u001b[34m██        \u001b[0m| 1/5 [00:02<00:09,  2.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 2 \tTrain_loss: 1.2621 | Train_acc: 57.7206 % | Validation_loss: 1.2333 | Validation_acc: 57.2500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|\u001b[34m████      \u001b[0m| 2/5 [00:04<00:07,  2.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 3 \tTrain_loss: 1.2234 | Train_acc: 60.4779 % | Validation_loss: 1.2061 | Validation_acc: 53.2500 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|\u001b[34m██████    \u001b[0m| 3/5 [00:07<00:04,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 4 \tTrain_loss: 1.1726 | Train_acc: 64.8897 % | Validation_loss: 1.3688 | Validation_acc: 25.6250 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|\u001b[34m████████  \u001b[0m| 4/5 [00:09<00:02,  2.49s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m \tTrain Epoch: 5 \tTrain_loss: 1.3351 | Train_acc: 29.2279 % | Validation_loss: 1.2625 | Validation_acc: 43.0000 %\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m save graph in  results/FL/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|\u001b[34m██████████\u001b[0m| 5/5 [00:12<00:00,  2.49s/it]\n",
      "DEBUG flwr 2024-07-14 03:07:23,309 | server.py:236 | fit_round 2 received 10 results and 0 failures\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.weight 3.814697265625e-06\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.0.bias 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.weight 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m features.3.bias 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.weight 4.76837158203125e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.0.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.2.bias 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.3.weights 7.152557373046875e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.weight 2.384185791015625e-07\n",
      "\u001b[36m(launch_and_fit pid=146489)\u001b[0m classifier.4.bias 4.76837158203125e-07\n",
      "Saving round 2 aggregated_parameters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-14 03:07:24,315 | server.py:173 | evaluate_round 2: strategy sampled 10 clients (out of 10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 7] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 9] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 2] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 3] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 8] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 5] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 6] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 0] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 4] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Run with homomorphic encryption\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m [Client 1] evaluate, config: {}\n",
      "\u001b[36m(launch_and_evaluate pid=146489)\u001b[0m Updated model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG flwr 2024-07-14 03:07:39,597 | server.py:187 | evaluate_round 2 received 10 results and 0 failures\n",
      "INFO flwr 2024-07-14 03:07:39,598 | server.py:153 | FL finished in 316.929091959988\n",
      "INFO flwr 2024-07-14 03:07:39,617 | app.py:225 | app_fit: losses_distributed [(1, 1.302988451719284), (2, 1.223114365339279)]\n",
      "INFO flwr 2024-07-14 03:07:39,618 | app.py:226 | app_fit: metrics_distributed_fit {}\n",
      "INFO flwr 2024-07-14 03:07:39,618 | app.py:227 | app_fit: metrics_distributed {'accuracy': [(1, 44.8875), (2, 45.6375)]}\n",
      "INFO flwr 2024-07-14 03:07:39,618 | app.py:228 | app_fit: losses_centralized []\n",
      "INFO flwr 2024-07-14 03:07:39,619 | app.py:229 | app_fit: metrics_centralized {}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation Time = 323.54564571380615 seconds\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "print(\"flwr\", fl.__version__)\n",
    "print(\"numpy\", np.__version__)\n",
    "print(\"torch\", torch.__version__)\n",
    "print(\"torchvision\", torchvision.__version__)\n",
    "print(f\"Training on {DEVICE}\")\n",
    "\n",
    "client_resources = None\n",
    "\n",
    "if DEVICE.type == \"cuda\":\n",
    "    client_resources = {\"num_cpus\":10, \"num_gpus\": 1}\n",
    "\n",
    "model_save = model_save\n",
    "path_yaml = yaml_path\n",
    "path_roc = roc_path\n",
    "results_save = save_results\n",
    "path_matrix = matrix_path\n",
    "batch_size = batch_size\n",
    "he = he\n",
    "secret_path = 'secret.pkl'\n",
    "server_path = 'secret.pkl'\n",
    "path_crypted = 'server.pkl'\n",
    "\n",
    "print(\"Start simulation\")\n",
    "start_simulation = time.time()\n",
    "fl.simulation.start_simulation(\n",
    "    client_fn=client_fn,\n",
    "    num_clients=number_clients,\n",
    "    config=fl.server.ServerConfig(num_rounds=rounds),\n",
    "    strategy=strategy,\n",
    "    client_resources=client_resources\n",
    ")\n",
    "print(f\"Simulation Time = {time.time() - start_simulation} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
